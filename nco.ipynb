{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, num_nodes, num_samples, random_seed=111):\n",
    "        super(TSPDataset, self).__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        self.data_set = []\n",
    "        for l in tqdm(range(num_samples)):\n",
    "            x = torch.FloatTensor(2, num_nodes).uniform_(0, 10)\n",
    "            self.data_set.append(x)\n",
    "\n",
    "        self.size = len(self.data_set)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 9404.69it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 5834.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_size = 100\n",
    "val_size = 10\n",
    "\n",
    "train_20_dataset = TSPDataset(20, train_size)\n",
    "val_20_dataset   = TSPDataset(20, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[7.1557, 9.1399, 2.8186, 2.5810, 6.3111, 6.0005, 9.3119, 2.1529, 6.0328,\n",
       "          7.3279, 1.8572, 5.1007, 7.5445, 2.8839, 5.7747, 0.3584, 1.0263, 3.4191,\n",
       "          4.3998, 6.3411],\n",
       "         [6.2239, 6.3345, 8.5797, 1.5720, 7.8532, 1.4575, 4.1766, 3.0467, 0.3819,\n",
       "          5.8046, 2.0890, 3.9636, 3.5268, 5.5136, 3.0214, 8.0456, 9.3314, 2.9508,\n",
       "          5.9819, 6.1105]]),\n",
       " tensor([[2.5441, 0.6741, 1.8583, 2.4797, 6.9311, 7.2554, 6.8444, 2.1323, 7.8210,\n",
       "          0.1328, 3.2433, 9.0768, 8.5738, 1.9826, 0.2668, 9.1534, 2.5898, 2.4681,\n",
       "          9.6348, 7.5225],\n",
       "         [2.0834, 1.1036, 6.1830, 8.0328, 7.1306, 2.8288, 2.0219, 9.7511, 6.0928,\n",
       "          4.9385, 3.3877, 7.8354, 5.4642, 9.6754, 1.6929, 7.9108, 6.8692, 2.6057,\n",
       "          3.2937, 1.7753]]),\n",
       " tensor([[6.4036, 1.9068, 5.3966, 6.0742, 6.5540, 9.6368, 4.8879, 3.8606, 1.8934,\n",
       "          8.9973, 3.4416, 6.0871, 7.2373, 9.9027, 5.0345, 2.9049, 3.1243, 1.9703,\n",
       "          4.8731, 3.8259],\n",
       "         [2.0718, 3.5871, 4.9036, 5.2842, 7.4665, 8.0870, 6.2307, 8.7173, 2.0936,\n",
       "          9.2061, 7.7457, 8.7058, 5.9095, 3.3843, 7.5797, 3.0173, 5.4609, 8.4850,\n",
       "          9.6380, 8.4478]]),\n",
       " tensor([[2.4068, 6.5766, 7.2821, 9.3233, 9.1226, 3.0242, 3.0098, 0.8172, 8.5136,\n",
       "          4.2961, 0.6619, 6.6750, 6.7147, 5.9917, 2.1640, 2.0533, 9.6465, 6.6055,\n",
       "          3.7772, 1.3006],\n",
       "         [1.8410, 6.9406, 5.9632, 9.6370, 8.3971, 4.3367, 1.4416, 2.4012, 4.6876,\n",
       "          3.2126, 6.7961, 1.6972, 2.7245, 0.2820, 4.2737, 6.7407, 3.5949, 5.3339,\n",
       "          4.1473, 4.6725]]),\n",
       " tensor([[7.5150, 7.9495, 3.7122, 1.1984, 5.4507, 4.8908, 8.4826, 8.4446, 9.4812,\n",
       "          2.5645, 8.7164, 9.0856, 9.7718, 5.1111, 8.5467, 3.1295, 5.5886, 0.1574,\n",
       "          5.1317, 1.5755],\n",
       "         [4.9866, 9.5127, 5.1067, 4.2722, 1.4298, 7.2487, 3.6042, 7.8851, 5.0511,\n",
       "          4.7155, 1.0176, 7.9525, 0.0975, 6.0786, 2.9511, 6.8556, 8.8781, 8.1943,\n",
       "          3.2853, 3.6646]]),\n",
       " tensor([[1.3141, 6.8870, 9.0517, 7.6375, 0.8608, 7.8961, 8.8085, 3.2875, 8.1116,\n",
       "          8.2197, 1.7227, 5.8257, 4.8764, 6.8614, 2.4305, 5.6576, 4.7861, 3.6969,\n",
       "          2.2790, 5.3742],\n",
       "         [1.4254, 3.7969, 9.8810, 6.5955, 1.1790, 3.4475, 8.4058, 5.1732, 7.3978,\n",
       "          2.8838, 4.6923, 3.3787, 4.1817, 4.7239, 7.6559, 6.3957, 6.7138, 4.0876,\n",
       "          9.7945, 6.8526]]),\n",
       " tensor([[7.7518, 2.6154, 5.2211, 6.1903, 2.5297, 7.3702, 1.8680, 1.1930, 9.2466,\n",
       "          6.4814, 9.9000, 6.7342, 3.7631, 9.4527, 9.4817, 0.0962, 5.9289, 4.5607,\n",
       "          9.1251, 8.0056],\n",
       "         [7.6566, 2.0662, 4.3982, 9.2892, 1.8863, 5.8573, 8.0778, 2.5982, 1.4336,\n",
       "          1.6960, 8.5803, 8.1123, 6.2300, 9.7427, 2.8161, 5.4672, 5.0495, 1.1925,\n",
       "          6.4043, 6.6958]]),\n",
       " tensor([[1.2192, 5.7303, 9.0272, 7.2414, 1.8924, 0.6097, 9.9363, 7.3730, 1.9856,\n",
       "          0.1969, 1.4463, 4.7531, 1.8784, 9.6582, 2.6530, 2.2307, 5.8303, 9.3564,\n",
       "          7.2309, 1.6520],\n",
       "         [6.8136, 5.6720, 1.8836, 4.7364, 9.0572, 0.0181, 5.0478, 6.6939, 9.1840,\n",
       "          2.8432, 8.7062, 2.9385, 4.7555, 6.4093, 2.0370, 5.1914, 9.9307, 7.1239,\n",
       "          6.4066, 8.6089]]),\n",
       " tensor([[7.6642, 6.1856, 5.9356, 2.1679, 0.1347, 0.3963, 2.9740, 3.7994, 2.6360,\n",
       "          2.9457, 8.9796, 8.2064, 9.6763, 1.7113, 7.6651, 7.6531, 1.7376, 6.1974,\n",
       "          8.2902, 4.0195],\n",
       "         [2.8075, 6.8109, 6.7721, 2.4659, 9.3041, 5.4699, 6.8659, 2.1395, 0.0797,\n",
       "          0.9822, 7.4265, 2.4320, 8.5421, 6.2824, 0.0588, 5.1889, 8.0560, 1.9539,\n",
       "          5.7769, 3.3893]]),\n",
       " tensor([[1.0069, 2.5620, 2.2058, 0.2470, 5.5204, 5.5772, 8.0709, 9.3327, 6.2251,\n",
       "          5.9011, 2.7470, 4.5471, 3.2358, 3.9726, 0.9202, 7.4995, 6.7032, 4.4498,\n",
       "          2.3032, 1.8646],\n",
       "         [6.1292, 0.8827, 3.0018, 6.5803, 7.4002, 3.4483, 8.5878, 4.4617, 5.5376,\n",
       "          7.5584, 8.2520, 2.6029, 2.8607, 1.4137, 7.7997, 3.6988, 3.2029, 3.7128,\n",
       "          2.1780, 6.1579]]),\n",
       " tensor([[3.5683, 0.8976, 7.2789, 9.6548, 3.7801, 8.1846, 1.0238, 8.8862, 0.0126,\n",
       "          5.4344, 0.6626, 2.7746, 9.2835, 3.6478, 6.2930, 4.7135, 5.7159, 9.1697,\n",
       "          8.5654, 5.4634],\n",
       "         [2.3031, 4.6216, 7.3185, 6.3116, 3.9284, 2.1469, 1.0207, 8.8375, 4.4728,\n",
       "          5.8446, 9.1171, 7.8940, 5.8081, 9.1301, 5.1740, 0.2892, 3.9299, 6.5944,\n",
       "          4.9009, 7.2092]]),\n",
       " tensor([[7.6518, 5.7378, 2.0820, 6.0340, 8.5694, 3.7098, 7.5163, 5.3171, 3.5993,\n",
       "          4.6008, 8.3734, 8.3389, 0.9190, 6.6953, 0.7299, 9.7951, 4.7643, 4.1969,\n",
       "          0.7313, 6.4540],\n",
       "         [7.4881, 3.5296, 0.0905, 9.0397, 7.6171, 4.2677, 0.4649, 0.0681, 0.2347,\n",
       "          3.1126, 0.7717, 0.1251, 6.3615, 2.6329, 5.1303, 5.3213, 8.6539, 2.1189,\n",
       "          8.7769, 1.2438]]),\n",
       " tensor([[7.2467, 2.6829, 3.0645, 7.3134, 6.8623, 4.5723, 8.9159, 9.7703, 5.1223,\n",
       "          7.0993, 2.3433, 1.4486, 5.6507, 0.3829, 0.9065, 2.2527, 9.5411, 4.2197,\n",
       "          6.5022, 1.6407],\n",
       "         [6.7592, 7.1017, 6.9549, 2.0991, 0.7435, 2.0203, 8.4516, 3.8440, 4.8948,\n",
       "          9.4639, 1.7289, 8.9485, 3.2220, 9.4547, 3.9288, 3.1552, 3.1105, 7.6896,\n",
       "          5.0945, 6.7243]]),\n",
       " tensor([[4.1716, 7.1349, 9.4508, 7.8419, 6.8183, 1.2177, 6.5396, 1.7201, 7.2869,\n",
       "          3.2361, 7.2936, 3.9711, 3.7804, 9.6197, 1.3161, 8.7382, 5.2577, 6.5251,\n",
       "          4.4739, 4.9596],\n",
       "         [5.9693, 6.9581, 6.8316, 1.5186, 7.3813, 4.0504, 7.1532, 6.6957, 7.4825,\n",
       "          4.8602, 1.7115, 8.2090, 0.4237, 7.6148, 0.7154, 0.9498, 7.5618, 1.2713,\n",
       "          6.8090, 0.7867]]),\n",
       " tensor([[5.0738, 1.5215, 3.3537, 9.8196, 7.0231, 4.0796, 7.9871, 9.6050, 8.6795,\n",
       "          6.2752, 0.8297, 4.8607, 7.1048, 4.9296, 1.2320, 1.6115, 9.7635, 0.8146,\n",
       "          8.6701, 2.1615],\n",
       "         [1.4170, 3.1832, 7.4508, 0.0636, 6.4065, 2.3176, 2.9742, 5.8526, 1.8225,\n",
       "          4.7623, 1.4801, 0.8284, 5.8599, 0.3705, 6.9987, 7.6481, 6.9180, 5.6565,\n",
       "          2.3278, 8.2887]]),\n",
       " tensor([[2.0856, 1.3939, 0.1049, 6.0018, 4.1174, 2.9822, 8.4434, 0.1441, 9.3320,\n",
       "          0.2940, 5.0306, 3.0900, 5.9748, 3.1000, 3.9231, 1.6851, 6.7256, 0.8331,\n",
       "          2.6189, 1.9082],\n",
       "         [8.5916, 7.6173, 2.0497, 5.7995, 9.8064, 8.4664, 5.2255, 8.3181, 7.6020,\n",
       "          1.2986, 2.1761, 6.1793, 0.7468, 7.7314, 4.9564, 3.4047, 6.8969, 3.2542,\n",
       "          4.7603, 0.4859]]),\n",
       " tensor([[9.5936, 1.8675, 0.5819, 8.4358, 9.3060, 8.2489, 1.2721, 7.4947, 4.9130,\n",
       "          3.9320, 5.5383, 8.5968, 3.2608, 5.5080, 4.0708, 4.5197, 7.9656, 7.4145,\n",
       "          0.3811, 1.5201],\n",
       "         [3.2995, 8.5789, 8.7728, 9.4322, 2.6786, 0.3081, 2.4655, 2.4951, 3.3221,\n",
       "          3.6276, 1.0252, 6.7912, 0.1821, 9.6604, 6.1988, 3.6663, 8.3789, 5.5199,\n",
       "          0.1381, 3.3280]]),\n",
       " tensor([[4.4481, 7.4135, 5.1052, 7.1164, 9.2850, 7.7234, 5.9298, 1.1924, 6.2134,\n",
       "          8.9034, 5.4629, 4.7240, 4.3217, 9.6502, 5.0579, 3.7020, 1.8237, 1.5599,\n",
       "          2.2847, 1.6674],\n",
       "         [9.4461, 1.9107, 0.2705, 6.2772, 1.4058, 8.1762, 5.5405, 3.0747, 6.4579,\n",
       "          5.9492, 6.5829, 1.5085, 8.0058, 3.7850, 5.4602, 9.3193, 9.6506, 8.1875,\n",
       "          0.1975, 1.9080]]),\n",
       " tensor([[2.6950, 1.7279, 7.1654, 6.2691, 4.0366, 0.0775, 0.6849, 8.0625, 6.6347,\n",
       "          7.4057, 7.1304, 0.8798, 7.6720, 8.7686, 4.5673, 0.8071, 6.7736, 5.8329,\n",
       "          6.6006, 9.5965],\n",
       "         [7.8062, 0.1459, 8.2019, 5.5908, 8.5894, 1.4349, 1.6842, 1.4743, 4.5852,\n",
       "          6.8161, 7.2435, 1.9877, 2.7206, 8.7665, 8.1213, 8.4653, 8.9911, 8.8430,\n",
       "          5.2151, 5.3871]]),\n",
       " tensor([[1.7233, 7.7859, 0.2142, 5.0244, 4.7342, 2.0180, 9.2370, 7.9901, 7.8169,\n",
       "          4.7308, 8.7193, 2.9190, 5.9526, 0.4528, 3.1142, 8.8985, 6.4413, 8.1677,\n",
       "          7.8631, 7.0666],\n",
       "         [9.9762, 9.4512, 1.4810, 9.3489, 2.0453, 0.0540, 6.7082, 6.1643, 3.3579,\n",
       "          2.2750, 1.6259, 7.2953, 0.4500, 3.0397, 1.4464, 3.5644, 1.7091, 8.2686,\n",
       "          6.9352, 0.0450]]),\n",
       " tensor([[7.0134, 5.5441, 8.7282, 4.4477, 8.4939, 0.1599, 8.2962, 3.4106, 9.7942,\n",
       "          2.3775, 4.7256, 1.1809, 5.3689, 3.3592, 8.2092, 6.0927, 8.1016, 5.2878,\n",
       "          6.3052, 9.4013],\n",
       "         [1.4685, 9.7474, 7.5010, 6.4988, 5.8415, 6.5288, 2.0835, 9.7070, 2.4874,\n",
       "          3.5678, 8.0206, 8.0076, 3.4745, 2.5939, 0.4564, 2.3822, 3.0662, 4.7002,\n",
       "          8.5324, 7.0663]]),\n",
       " tensor([[6.3754, 4.6581, 5.3052, 0.2801, 4.0564, 7.0261, 1.8309, 5.8493, 3.5839,\n",
       "          8.1507, 0.0289, 6.2117, 2.3502, 9.5384, 4.6883, 6.6852, 8.3275, 1.6691,\n",
       "          1.9992, 6.0901],\n",
       "         [6.9141, 1.7389, 7.5461, 6.3804, 6.8560, 7.1207, 7.5440, 0.9071, 5.3694,\n",
       "          5.4702, 8.8869, 6.2288, 4.1121, 6.2942, 6.4199, 9.6926, 6.6810, 9.5129,\n",
       "          8.4603, 0.9320]]),\n",
       " tensor([[0.6100, 8.3978, 0.1048, 0.7123, 0.3730, 9.8010, 5.8806, 7.0765, 1.8250,\n",
       "          4.3592, 5.6582, 7.0837, 2.2917, 2.8089, 2.8690, 2.9177, 7.6064, 8.1293,\n",
       "          5.0960, 2.3332],\n",
       "         [9.3537, 0.5712, 5.4925, 8.9588, 2.1083, 5.8092, 8.3485, 9.2080, 6.7267,\n",
       "          9.0595, 4.7552, 7.5333, 5.8888, 2.1485, 6.0038, 6.4690, 4.0141, 7.4882,\n",
       "          8.0162, 9.2874]]),\n",
       " tensor([[9.6557, 8.4034, 7.7403, 7.6882, 6.8440, 1.2742, 2.7021, 1.2384, 1.8500,\n",
       "          3.9937, 5.5245, 7.1384, 2.2059, 0.9763, 0.9591, 5.6268, 5.1879, 3.9989,\n",
       "          2.8569, 3.3787],\n",
       "         [5.3647, 4.1064, 5.5898, 4.1068, 1.7339, 4.2433, 1.6107, 4.1801, 8.3402,\n",
       "          1.7703, 8.6209, 1.0317, 5.6147, 6.8437, 8.9055, 9.1335, 5.8920, 2.9937,\n",
       "          9.8073, 4.8481]]),\n",
       " tensor([[2.7919, 5.6854, 2.6400, 7.2682, 6.0316, 8.5764, 4.8042, 3.5953, 8.3276,\n",
       "          7.7686, 0.6933, 4.8000, 8.6253, 9.8279, 3.6675, 5.1686, 3.2656, 0.1399,\n",
       "          8.4412, 2.0276],\n",
       "         [2.2967, 7.6084, 7.4470, 3.9355, 8.8799, 0.0842, 0.7640, 4.6371, 8.3356,\n",
       "          0.7547, 7.8796, 3.3595, 3.8095, 3.0553, 4.1821, 7.8098, 8.3228, 5.8138,\n",
       "          2.7651, 5.1248]]),\n",
       " tensor([[2.5164, 0.5204, 3.9890, 3.1276, 4.2107, 2.0401, 3.6876, 9.9616, 5.6611,\n",
       "          4.1073, 0.2212, 2.4377, 9.2389, 9.3904, 6.6429, 4.4602, 0.8500, 3.9590,\n",
       "          2.0171, 2.1761],\n",
       "         [2.1046, 7.1257, 5.1414, 6.4716, 0.6297, 2.2257, 4.2355, 3.6612, 2.1352,\n",
       "          3.0730, 7.8276, 4.1772, 9.0314, 3.6676, 5.2214, 1.5410, 5.4265, 2.2182,\n",
       "          8.3575, 7.6363]]),\n",
       " tensor([[7.0638, 5.2376, 7.4510, 1.6863, 6.7542, 0.2216, 7.4349, 5.8513, 7.1435,\n",
       "          6.9120, 6.0803, 8.0743, 3.0889, 2.0389, 8.1834, 9.5950, 0.8897, 4.7503,\n",
       "          7.0966, 4.2835],\n",
       "         [5.7811, 0.8812, 1.6586, 7.7594, 9.5062, 6.5487, 5.9287, 1.8280, 9.1861,\n",
       "          8.1920, 5.9264, 0.4144, 7.5161, 9.3130, 7.1536, 6.1069, 1.1450, 2.3000,\n",
       "          2.7870, 6.6370]]),\n",
       " tensor([[0.8227, 5.5964, 4.0749, 3.5149, 6.7601, 5.7910, 7.1493, 0.5564, 5.7186,\n",
       "          1.7346, 2.6051, 6.3799, 4.0310, 9.9768, 8.7738, 0.3641, 9.4895, 5.8559,\n",
       "          0.1485, 3.2761],\n",
       "         [6.1787, 0.5758, 6.2638, 7.1800, 3.1709, 0.3328, 8.7488, 8.7317, 6.0358,\n",
       "          9.8274, 3.0736, 6.5637, 3.6202, 1.1858, 5.7138, 5.4569, 6.6088, 3.2156,\n",
       "          6.0770, 2.6204]]),\n",
       " tensor([[0.6444, 4.4763, 0.5538, 8.1351, 3.1018, 7.4180, 1.4046, 5.2659, 2.4344,\n",
       "          3.0001, 9.1543, 1.8395, 0.5635, 5.7234, 3.3043, 9.8650, 7.8620, 8.2801,\n",
       "          0.3884, 1.4170],\n",
       "         [0.8801, 9.8594, 6.7793, 7.7386, 0.5549, 0.6100, 7.6872, 9.2239, 4.7600,\n",
       "          7.8811, 0.5477, 0.2651, 1.9324, 1.6265, 6.4915, 0.7603, 5.3881, 4.2263,\n",
       "          3.1451, 2.3149]]),\n",
       " tensor([[3.2409, 6.1804, 6.9918, 5.0488, 0.4767, 8.3264, 5.1890, 4.3931, 3.0755,\n",
       "          9.3980, 5.6000, 6.7998, 4.6921, 5.8969, 5.3122, 6.5312, 5.5704, 3.2340,\n",
       "          7.8894, 9.0495],\n",
       "         [2.4133, 6.3788, 7.9135, 2.2962, 0.9090, 4.9776, 4.5471, 8.8915, 2.8932,\n",
       "          3.6981, 5.2414, 4.4534, 8.9097, 0.2306, 5.1941, 1.4948, 7.3908, 9.0058,\n",
       "          2.2638, 8.2225]]),\n",
       " tensor([[0.2799, 2.9144, 0.7165, 8.5658, 8.0645, 9.5823, 7.4804, 0.2840, 5.4002,\n",
       "          6.4331, 8.3696, 7.1484, 7.3553, 8.4382, 8.1406, 9.6600, 3.3095, 6.6966,\n",
       "          8.0465, 6.5363],\n",
       "         [7.9217, 1.7411, 5.6839, 2.7528, 3.6676, 3.2434, 7.4401, 1.5435, 4.9585,\n",
       "          7.9209, 1.4224, 0.8150, 2.3905, 6.5951, 7.2988, 5.2205, 0.2037, 5.2460,\n",
       "          6.8190, 1.7459]]),\n",
       " tensor([[1.5564, 4.9535, 1.1757, 8.2959, 7.1601, 4.3662, 8.0579, 3.9843, 6.0499,\n",
       "          6.5915, 0.7448, 7.8108, 9.6218, 2.4870, 8.9358, 6.7319, 1.5145, 4.5536,\n",
       "          9.5225, 7.9516],\n",
       "         [4.5755, 8.3884, 2.8924, 0.0542, 9.4548, 3.6324, 0.5005, 9.9484, 8.7464,\n",
       "          2.3719, 1.1388, 9.4642, 1.6204, 1.0490, 4.3339, 9.9374, 1.9697, 0.9249,\n",
       "          0.3895, 7.7148]]),\n",
       " tensor([[1.1109, 9.8022, 0.2876, 1.7300, 2.4366, 1.0699, 8.1283, 8.1308, 8.0850,\n",
       "          7.8063, 2.6549, 9.8616, 2.5631, 6.6331, 8.2048, 4.9777, 4.0940, 9.4091,\n",
       "          7.8629, 5.9832],\n",
       "         [5.2946, 3.6962, 3.1898, 4.0324, 4.2979, 7.3438, 6.3382, 2.7169, 0.1735,\n",
       "          7.4432, 6.0867, 5.3644, 9.3466, 1.4065, 7.6098, 3.7024, 0.4693, 1.1850,\n",
       "          8.9517, 8.1027]]),\n",
       " tensor([[4.5047, 7.4980, 7.7242, 8.9954, 6.8213, 8.5579, 0.7603, 2.1688, 9.9530,\n",
       "          7.0894, 5.5274, 8.1333, 9.1192, 3.7683, 6.0892, 8.4722, 6.8167, 5.5188,\n",
       "          7.5296, 7.7999],\n",
       "         [4.4121, 9.4027, 8.7291, 4.3431, 4.9784, 8.0577, 7.6215, 1.7149, 7.8455,\n",
       "          8.5337, 1.8212, 2.9285, 2.4444, 1.8240, 6.8385, 7.6191, 9.7228, 4.3832,\n",
       "          0.9966, 1.5393]]),\n",
       " tensor([[6.3057, 7.4124, 4.3210, 0.7071, 9.6490, 3.7630, 2.9270, 3.0141, 2.6843,\n",
       "          4.5787, 9.3660, 1.9602, 6.7794, 3.5151, 9.9157, 8.2295, 7.0916, 4.1479,\n",
       "          6.0799, 2.8661],\n",
       "         [0.9612, 8.9987, 4.5115, 3.0588, 6.1524, 9.4851, 5.2698, 2.2797, 8.3011,\n",
       "          2.9391, 9.8734, 7.8774, 5.3236, 2.7997, 9.0566, 7.9339, 9.8035, 9.0215,\n",
       "          7.8758, 2.6169]]),\n",
       " tensor([[4.5332, 0.7251, 5.2589, 6.7900, 3.0638, 1.0372, 3.6990, 4.5804, 3.1334,\n",
       "          7.7075, 6.7135, 9.8087, 0.0615, 9.1363, 7.5127, 3.8998, 0.1322, 0.1563,\n",
       "          9.9180, 7.4966],\n",
       "         [2.2410, 1.5022, 4.2604, 5.2904, 9.3029, 7.2822, 5.1115, 5.9715, 9.1849,\n",
       "          4.0371, 6.5608, 6.2369, 6.6621, 2.0349, 2.1130, 6.3258, 8.4773, 9.7437,\n",
       "          0.7400, 6.5303]]),\n",
       " tensor([[5.1620, 7.2620, 5.0050, 0.8221, 5.4611, 1.8201, 8.5559, 0.4516, 2.5986,\n",
       "          3.1451, 9.1461, 9.3132, 2.2908, 9.4095, 1.5893, 1.6581, 0.0401, 5.6265,\n",
       "          6.2473, 6.8658],\n",
       "         [5.8104, 8.3293, 4.7237, 9.8748, 1.8133, 9.0821, 8.7702, 8.5745, 0.2118,\n",
       "          9.0305, 9.4893, 8.9159, 0.3905, 7.1754, 4.5779, 9.0841, 6.6679, 3.4647,\n",
       "          7.1568, 3.4243]]),\n",
       " tensor([[0.3250, 4.1269, 2.1493, 5.9119, 2.4799, 6.3105, 7.3611, 5.6585, 2.4677,\n",
       "          9.5895, 2.3153, 7.2564, 3.9396, 0.8047, 8.6735, 5.5887, 6.8176, 0.3101,\n",
       "          3.4639, 1.5218],\n",
       "         [2.6507, 0.2896, 2.8886, 5.4573, 8.6256, 6.2007, 0.5747, 8.8901, 9.0787,\n",
       "          9.1036, 1.5360, 6.0261, 4.8823, 5.9594, 7.5259, 8.4200, 8.9475, 6.9142,\n",
       "          8.8029, 1.0548]]),\n",
       " tensor([[8.6560, 6.0853, 9.8820, 2.3067, 9.8956, 2.2885, 2.4062, 6.3044, 1.3023,\n",
       "          8.4415, 9.0182, 6.2392, 8.0222, 8.8878, 5.2769, 0.5786, 2.2729, 0.1694,\n",
       "          4.7323, 0.8931],\n",
       "         [0.5320, 6.0838, 8.7578, 1.0704, 1.4836, 7.5005, 8.9040, 5.3726, 5.5720,\n",
       "          4.8733, 6.8463, 6.2223, 1.8107, 9.1837, 1.3791, 2.0273, 4.4123, 5.0878,\n",
       "          4.4913, 9.1766]]),\n",
       " tensor([[9.2372e+00, 7.7304e+00, 4.9856e+00, 2.8248e+00, 8.6916e+00, 5.9329e+00,\n",
       "          6.4937e+00, 5.5291e+00, 1.8501e+00, 6.6220e-01, 2.2581e+00, 3.3252e+00,\n",
       "          8.2777e+00, 8.6341e+00, 8.9327e+00, 7.3397e+00, 9.9563e+00, 6.5196e+00,\n",
       "          4.8157e+00, 8.0392e+00],\n",
       "         [7.8574e+00, 4.4044e+00, 3.1985e+00, 1.1600e+00, 4.7180e+00, 4.2862e-03,\n",
       "          4.7257e+00, 7.0739e+00, 4.2256e+00, 9.8612e+00, 3.5736e+00, 9.3546e+00,\n",
       "          4.8575e+00, 2.5623e+00, 3.5517e+00, 4.2272e+00, 2.9651e+00, 1.5524e+00,\n",
       "          8.7164e+00, 4.4845e+00]]),\n",
       " tensor([[7.2004, 7.9445, 1.4026, 5.3010, 3.8780, 9.1265, 3.9916, 2.2717, 8.7751,\n",
       "          7.3876, 6.0252, 6.8283, 5.1813, 6.9995, 5.8413, 0.7990, 6.1068, 8.0663,\n",
       "          7.6362, 7.5246],\n",
       "         [7.3138, 9.9507, 1.2257, 5.9243, 0.0239, 8.4711, 3.0410, 3.6951, 1.0848,\n",
       "          5.3891, 9.2432, 5.4826, 1.1539, 6.2499, 2.6121, 5.3209, 9.3097, 4.7332,\n",
       "          3.7231, 7.7638]]),\n",
       " tensor([[6.6106, 1.9554, 0.5896, 3.8252, 6.4864, 0.3938, 6.9133, 7.3901, 8.4286,\n",
       "          7.9799, 3.6753, 6.3832, 0.8695, 0.2598, 3.4314, 3.1314, 9.6911, 8.2124,\n",
       "          2.6223, 7.7442],\n",
       "         [9.2804, 8.3543, 9.4464, 4.8784, 2.6077, 4.6906, 2.3551, 0.0670, 3.7943,\n",
       "          9.1820, 5.9705, 1.4900, 4.7139, 8.8349, 4.1654, 6.1497, 1.3937, 6.1232,\n",
       "          0.6779, 6.7958]]),\n",
       " tensor([[1.6440, 4.9769, 1.6218, 5.1062, 5.7586, 8.1382, 6.9510, 4.2079, 8.9196,\n",
       "          1.4314, 4.5357, 6.9961, 6.6274, 0.5441, 3.4937, 1.9946, 9.2806, 8.5141,\n",
       "          3.3621, 0.2074],\n",
       "         [1.0456, 3.7463, 1.4616, 5.0987, 8.7039, 6.8443, 9.4404, 6.7862, 0.9852,\n",
       "          8.3309, 9.5189, 1.7548, 8.2505, 3.9218, 7.5370, 4.9180, 9.4522, 4.8803,\n",
       "          4.9208, 6.0320]]),\n",
       " tensor([[1.7996, 2.7117, 4.3990, 6.3340, 2.0886, 7.9877, 7.4673, 7.2579, 8.7788,\n",
       "          1.3260, 7.5950, 2.7109, 7.4780, 9.2188, 7.7231, 3.8019, 1.3669, 1.4622,\n",
       "          6.3683, 3.5132],\n",
       "         [4.0508, 4.2144, 3.8148, 3.2337, 5.7856, 4.2510, 3.8631, 4.0068, 6.8938,\n",
       "          5.4461, 8.2090, 5.5163, 0.3550, 0.1189, 1.1371, 0.6878, 5.8376, 1.7268,\n",
       "          4.4467, 5.5522]]),\n",
       " tensor([[8.8751, 3.9326, 0.1299, 1.6246, 3.1928, 6.7242, 7.1310, 2.1564, 2.1297,\n",
       "          5.4935, 0.2782, 1.1953, 2.9933, 4.0316, 2.7755, 8.9929, 2.8114, 3.7761,\n",
       "          0.1506, 7.5354],\n",
       "         [3.9077, 8.4681, 3.7655, 1.7146, 4.7519, 3.2924, 4.6077, 1.3255, 5.2683,\n",
       "          6.8800, 6.6447, 0.2330, 2.8455, 2.3683, 1.3178, 1.3345, 7.2472, 1.7410,\n",
       "          2.6136, 4.0048]]),\n",
       " tensor([[9.9835, 9.8667, 1.9333, 3.7350, 0.9883, 6.2777, 1.0489, 9.0912, 0.8274,\n",
       "          8.7688, 9.8411, 6.8511, 3.8894, 7.8963, 1.7816, 6.4651, 2.7599, 1.9635,\n",
       "          1.9113, 0.8558],\n",
       "         [2.6991, 4.8164, 8.9549, 8.2224, 4.5811, 7.5279, 6.0350, 3.3614, 8.3740,\n",
       "          0.3095, 5.5522, 1.6913, 6.2023, 0.3289, 4.6371, 8.2002, 9.4603, 0.4614,\n",
       "          9.8946, 2.0877]]),\n",
       " tensor([[4.9585, 9.9645, 2.4921, 4.1395, 4.1574, 3.5701, 7.6016, 8.4156, 2.3942,\n",
       "          2.7317, 7.3749, 9.5376, 7.5519, 9.1677, 8.8761, 8.1539, 0.3882, 1.3417,\n",
       "          7.4025, 1.7098],\n",
       "         [6.7408, 4.0170, 2.3136, 3.7745, 7.2295, 3.3275, 3.8112, 1.6629, 9.5254,\n",
       "          6.5096, 5.1725, 8.5030, 2.6387, 6.4938, 0.7983, 8.4245, 3.2767, 2.5075,\n",
       "          9.7473, 4.7319]]),\n",
       " tensor([[8.1349, 1.8800, 7.3011, 6.6405, 7.4341, 4.4422, 0.6673, 6.1930, 3.3232,\n",
       "          2.7629, 0.2252, 8.6578, 9.8859, 6.2367, 0.9007, 4.6461, 4.8743, 1.3944,\n",
       "          4.2950, 4.2088],\n",
       "         [5.0245, 2.0074, 0.5656, 5.8579, 6.2881, 2.0952, 4.0611, 4.1023, 5.7115,\n",
       "          6.5723, 0.7374, 4.7988, 4.3460, 0.6786, 7.4223, 2.3140, 1.8263, 2.0554,\n",
       "          4.8994, 2.6108]]),\n",
       " tensor([[8.6675, 9.2596, 5.7911, 0.9248, 6.3669, 4.4555, 3.8904, 1.9999, 5.2853,\n",
       "          5.8065, 1.0845, 2.2931, 6.6499, 4.0091, 6.6224, 6.1531, 0.5278, 0.1272,\n",
       "          8.4644, 0.8853],\n",
       "         [0.3024, 8.1651, 1.9931, 2.2502, 0.4719, 8.7785, 2.5513, 2.8352, 6.0011,\n",
       "          8.1152, 4.7501, 7.0210, 4.5558, 4.9666, 6.1983, 8.5810, 0.9975, 7.9013,\n",
       "          4.9681, 9.5932]]),\n",
       " tensor([[3.6425, 8.4788, 9.2803, 3.4276, 6.9676, 2.7787, 0.2567, 8.4303, 4.3118,\n",
       "          6.6829, 3.0229, 5.7933, 8.6024, 3.1488, 2.4041, 8.2732, 7.9481, 4.3371,\n",
       "          4.6243, 7.5354],\n",
       "         [3.9364, 8.1963, 1.8982, 1.5051, 8.0153, 2.0706, 2.7391, 1.1518, 3.8621,\n",
       "          3.1013, 1.0219, 0.9587, 3.6807, 4.7764, 8.8857, 6.8586, 7.2819, 3.7170,\n",
       "          2.8570, 3.3998]]),\n",
       " tensor([[2.5710, 2.1641, 3.7664, 7.5156, 9.8856, 4.6234, 9.1663, 7.0606, 6.8765,\n",
       "          9.9259, 3.2132, 7.9146, 6.8461, 3.7915, 5.6709, 2.6209, 2.7565, 8.7650,\n",
       "          1.3138, 1.6720],\n",
       "         [7.3076, 1.9843, 3.3832, 9.6992, 3.0364, 2.7780, 7.0664, 9.9175, 5.5759,\n",
       "          7.3247, 7.4150, 9.1672, 4.2404, 6.8342, 9.4511, 8.3666, 7.5409, 8.9269,\n",
       "          2.5296, 3.8022]]),\n",
       " tensor([[2.5167, 4.7639, 8.4193, 5.5355, 1.4438, 9.8230, 9.8471, 9.1437, 0.5771,\n",
       "          3.8150, 9.8314, 9.6271, 1.3610, 5.7463, 7.6171, 3.5519, 1.3903, 6.4669,\n",
       "          0.6547, 7.3398],\n",
       "         [2.6697, 8.6826, 1.2319, 6.2710, 2.8717, 2.5975, 2.8401, 5.3724, 5.8582,\n",
       "          2.9411, 3.0740, 3.5739, 1.4730, 1.3662, 8.9504, 8.6663, 0.4142, 2.7455,\n",
       "          9.6471, 3.9296]]),\n",
       " tensor([[6.5604, 4.1025, 4.7168, 7.2155, 7.4752, 2.2025, 4.4529, 4.5039, 9.2250,\n",
       "          3.9543, 0.5584, 7.8594, 6.4991, 4.0187, 8.7336, 6.7862, 6.1471, 0.4234,\n",
       "          1.2162, 1.4922],\n",
       "         [1.6650, 3.6166, 8.9192, 5.2940, 2.9024, 2.4519, 0.1521, 5.3378, 6.6889,\n",
       "          9.4660, 7.0664, 4.2879, 2.3370, 9.1764, 5.6957, 8.7820, 9.8890, 7.0363,\n",
       "          7.9283, 3.7755]]),\n",
       " tensor([[9.3731, 5.7659, 8.8594, 0.2500, 0.6359, 9.3190, 0.3806, 0.8557, 7.2456,\n",
       "          2.3633, 6.0744, 0.9145, 1.6260, 1.4189, 1.2018, 9.4040, 4.2693, 5.9161,\n",
       "          0.5807, 1.3249],\n",
       "         [3.7748, 3.1112, 4.5330, 1.6872, 6.8965, 9.5795, 5.0024, 4.1230, 6.5338,\n",
       "          8.9082, 7.7607, 4.1242, 4.0850, 8.4705, 9.6049, 5.4986, 2.7506, 0.9294,\n",
       "          8.2825, 0.9594]]),\n",
       " tensor([[2.6647, 7.1159, 2.3715, 4.6838, 2.6047, 9.9279, 6.6969, 9.9126, 8.8973,\n",
       "          1.6080, 7.5597, 1.9220, 1.6591, 3.3667, 6.7240, 7.3415, 7.7325, 0.2219,\n",
       "          6.4555, 7.3360],\n",
       "         [0.8690, 7.1551, 9.7736, 1.5173, 7.0193, 7.3676, 3.4980, 6.3162, 5.8488,\n",
       "          0.2928, 0.3785, 9.8653, 5.1368, 0.8883, 6.9550, 0.4785, 9.5561, 7.0322,\n",
       "          9.4373, 2.2961]]),\n",
       " tensor([[7.4483, 5.6547, 8.2262, 4.2931, 2.1014, 6.3775, 0.2532, 6.1893, 0.5827,\n",
       "          4.8583, 2.8784, 4.7874, 1.5942, 4.0051, 0.6956, 1.7205, 6.9774, 9.7736,\n",
       "          5.5541, 4.1975],\n",
       "         [5.2156, 5.4510, 5.7376, 3.3027, 4.4244, 1.7510, 7.3099, 2.6351, 0.4350,\n",
       "          7.1992, 1.0367, 8.2854, 4.9880, 3.3180, 8.4363, 8.3628, 2.4712, 6.0701,\n",
       "          6.1892, 1.5360]]),\n",
       " tensor([[5.3404, 8.7691, 6.5507, 7.1506, 7.1458, 3.8546, 6.5546, 7.4666, 5.9261,\n",
       "          3.7878, 9.0315, 3.3901, 3.8740, 0.4066, 7.1526, 7.6111, 3.5567, 5.3300,\n",
       "          2.8260, 3.4844],\n",
       "         [3.3895, 3.6636, 8.9830, 4.4035, 0.8043, 3.7090, 9.9321, 8.8566, 9.0746,\n",
       "          1.0941, 6.8260, 8.0946, 0.1343, 4.6345, 2.5141, 3.6887, 1.4611, 1.6306,\n",
       "          4.0920, 1.8638]]),\n",
       " tensor([[8.3971, 4.7746, 8.8925, 4.6550, 0.7894, 1.7584, 4.7041, 6.9479, 3.3479,\n",
       "          3.2467, 6.5061, 4.4072, 8.4009, 6.3599, 7.7182, 4.2760, 3.4934, 4.4031,\n",
       "          2.3631, 0.0627],\n",
       "         [8.9472, 7.3773, 8.8621, 2.4581, 8.9597, 5.4980, 7.1757, 9.3173, 6.8181,\n",
       "          5.3775, 5.6664, 4.4653, 1.4731, 9.1891, 0.5100, 3.0726, 1.3333, 7.4034,\n",
       "          1.9511, 4.8448]]),\n",
       " tensor([[6.4307, 2.7371, 2.5491, 9.8698, 3.2547, 8.1456, 1.3309, 2.8907, 5.7876,\n",
       "          3.4230, 4.6303, 6.4040, 0.5274, 3.3906, 6.7252, 9.0316, 0.2721, 2.1608,\n",
       "          9.8130, 6.8089],\n",
       "         [5.6182, 2.1330, 5.1467, 4.1354, 6.9327, 5.9020, 8.1222, 6.2504, 0.1105,\n",
       "          1.5003, 3.6745, 4.1815, 8.2868, 8.9827, 0.2640, 2.0173, 4.1821, 1.5142,\n",
       "          5.1417, 0.1889]]),\n",
       " tensor([[5.4534, 6.6235, 5.1926, 9.5698, 0.1124, 5.1832, 0.0890, 6.2627, 7.4042,\n",
       "          2.1229, 0.1391, 2.6369, 4.6402, 0.7694, 1.4298, 7.9589, 1.9861, 7.7689,\n",
       "          5.5134, 8.7128],\n",
       "         [4.5579, 2.8044, 6.9706, 4.8166, 6.1727, 1.9292, 7.6565, 9.4115, 8.6805,\n",
       "          0.7170, 5.9697, 0.4619, 5.2446, 0.7789, 1.7975, 2.4126, 7.6167, 7.5997,\n",
       "          1.6687, 9.3050]]),\n",
       " tensor([[7.7985, 8.8616, 4.3014, 3.1507, 5.9570, 5.6762, 2.5159, 2.8336, 0.4339,\n",
       "          0.1764, 8.1436, 8.1734, 1.2799, 5.0714, 6.0217, 7.6548, 9.1229, 9.7460,\n",
       "          2.9309, 2.0027],\n",
       "         [7.5199, 8.8949, 0.9469, 6.1255, 6.3509, 1.3799, 6.9096, 5.0797, 1.2074,\n",
       "          6.4153, 4.1932, 9.5670, 2.4742, 5.8273, 9.1059, 7.2375, 4.1790, 4.4985,\n",
       "          6.6708, 8.4776]]),\n",
       " tensor([[5.3059, 0.6950, 1.8833, 8.2506, 2.9816, 9.1216, 1.8128, 9.9150, 1.6398,\n",
       "          6.4186, 2.3718, 7.7131, 3.0695, 9.2997, 6.5567, 8.0986, 6.5076, 3.5206,\n",
       "          2.2721, 5.7382],\n",
       "         [1.7708, 1.3667, 9.5579, 6.1294, 4.0468, 2.6496, 2.2015, 5.8079, 1.5416,\n",
       "          5.4331, 1.5566, 6.7452, 1.0180, 3.5447, 7.8380, 4.2744, 4.0243, 1.1215,\n",
       "          0.5148, 0.7858]]),\n",
       " tensor([[7.8880, 6.9159, 3.0630, 2.0632, 4.4035, 7.6980, 2.6208, 5.1178, 0.8964,\n",
       "          2.7980, 0.9487, 0.4153, 9.3776, 3.8869, 5.8740, 4.8695, 5.3943, 0.4841,\n",
       "          4.6118, 6.5527],\n",
       "         [4.4451, 1.3852, 0.4094, 4.1052, 4.2173, 9.3795, 4.1863, 9.0560, 8.4229,\n",
       "          5.8372, 5.0320, 1.3052, 0.6080, 1.5459, 2.7417, 4.3231, 6.1279, 0.6057,\n",
       "          0.3162, 8.1987]]),\n",
       " tensor([[0.5101, 8.3527, 5.0733, 1.2311, 1.5906, 5.4008, 3.0171, 9.3187, 6.9266,\n",
       "          5.1272, 5.8197, 3.1878, 7.3459, 7.2722, 1.3694, 2.6918, 9.6394, 3.1255,\n",
       "          7.6383, 4.7265],\n",
       "         [3.5431, 6.4841, 4.8143, 1.7385, 2.4730, 6.9104, 8.7356, 3.0527, 0.4398,\n",
       "          9.9820, 9.0218, 2.4023, 5.9544, 8.5796, 3.1871, 7.7015, 7.6721, 2.8788,\n",
       "          7.9798, 0.8871]]),\n",
       " tensor([[9.2803, 5.1761, 4.3740, 0.5787, 3.2440, 5.6250, 9.6413, 2.3545, 2.6339,\n",
       "          5.9235, 4.4619, 1.2143, 9.6899, 2.0332, 5.7028, 3.8218, 7.7428, 3.7371,\n",
       "          5.3849, 7.8590],\n",
       "         [7.4950, 6.6128, 5.2893, 8.7956, 8.2597, 6.1158, 4.3959, 2.3698, 3.6828,\n",
       "          1.5491, 7.4315, 9.8759, 5.8321, 7.3841, 7.5573, 1.0078, 6.2830, 6.0925,\n",
       "          8.4838, 0.1709]]),\n",
       " tensor([[1.0463, 8.1325, 3.1944, 8.2655, 2.4601, 5.0649, 7.9214, 6.2795, 9.5380,\n",
       "          0.1510, 1.7965, 1.3822, 6.9768, 4.2268, 6.4066, 0.5213, 1.7517, 2.8675,\n",
       "          1.7406, 3.2833],\n",
       "         [7.8123, 2.0257, 0.7875, 5.0772, 3.1165, 1.5931, 2.6236, 8.9208, 0.4881,\n",
       "          7.8867, 5.7269, 6.8577, 0.4556, 4.5540, 1.1662, 5.0195, 0.3678, 4.3664,\n",
       "          4.5324, 1.5246]]),\n",
       " tensor([[3.2090, 5.9598, 7.5428, 0.4310, 0.7963, 8.3832, 2.1765, 7.3073, 2.5196,\n",
       "          5.5770, 6.0813, 3.3227, 6.8821, 7.4306, 3.2654, 0.4824, 7.1790, 0.6006,\n",
       "          9.2702, 1.4033],\n",
       "         [8.1075, 7.7049, 2.8466, 5.6094, 5.8592, 3.5937, 8.7040, 8.7836, 6.9925,\n",
       "          3.0226, 8.6638, 0.2694, 7.6408, 7.6117, 5.6491, 8.5448, 3.3791, 3.5350,\n",
       "          6.7266, 0.4738]]),\n",
       " tensor([[9.4595, 6.3203, 5.9622, 4.7452, 7.7865, 1.3900, 0.0431, 0.9139, 4.1044,\n",
       "          5.6804, 1.6490, 6.1439, 2.7452, 2.5369, 6.5427, 1.4477, 6.9793, 4.9216,\n",
       "          8.1034, 0.8687],\n",
       "         [1.0590, 5.9513, 6.0868, 2.1833, 5.1840, 5.1204, 3.5596, 2.8377, 8.9384,\n",
       "          8.4374, 4.5995, 6.7574, 8.5311, 0.9465, 1.4260, 9.7250, 7.5987, 2.9688,\n",
       "          8.9727, 3.5643]]),\n",
       " tensor([[0.6417, 9.7171, 2.3221, 2.0916, 3.5549, 9.9276, 3.7563, 6.0191, 2.7548,\n",
       "          7.1680, 9.9202, 3.3726, 5.5797, 9.6198, 2.2031, 5.7168, 7.1230, 4.0961,\n",
       "          7.7924, 7.6491],\n",
       "         [9.5095, 8.4919, 7.7124, 9.2875, 0.5483, 7.6953, 0.3119, 1.3230, 6.4420,\n",
       "          7.7029, 4.6124, 3.8993, 6.6264, 5.7402, 0.9345, 4.8413, 7.6970, 4.8817,\n",
       "          5.0449, 0.8685]]),\n",
       " tensor([[3.8308, 3.2870, 2.2687, 8.9724, 0.6212, 5.8854, 4.3633, 5.4638, 9.1215,\n",
       "          8.2054, 5.4595, 4.9642, 8.0916, 6.6963, 4.4065, 1.6597, 1.2780, 4.1332,\n",
       "          0.1296, 3.0683],\n",
       "         [1.8969, 1.9478, 8.1599, 6.2135, 5.1859, 8.3101, 9.3734, 8.0082, 2.7632,\n",
       "          2.3002, 6.5906, 9.0710, 8.6590, 5.0889, 5.2378, 7.3611, 9.5141, 4.3971,\n",
       "          7.8958, 7.3496]]),\n",
       " tensor([[4.8429, 2.6485, 6.2142, 0.6873, 1.9012, 2.3597, 0.6779, 7.1421, 8.1081,\n",
       "          8.9347, 1.7664, 2.8279, 8.5779, 9.3149, 3.4404, 0.5966, 2.5824, 6.6980,\n",
       "          5.6759, 3.6616],\n",
       "         [7.1960, 1.6399, 3.3071, 2.0751, 6.2195, 7.9122, 6.5950, 8.6515, 4.3207,\n",
       "          5.8509, 0.5498, 3.6932, 7.7203, 3.0739, 6.3799, 3.4329, 8.7402, 1.4830,\n",
       "          8.9650, 0.3628]]),\n",
       " tensor([[9.3986, 9.1536, 1.4625, 4.4914, 4.0946, 5.6478, 0.5437, 2.4384, 5.5744,\n",
       "          2.9343, 6.4058, 0.5397, 7.2278, 5.0788, 0.8014, 5.3186, 4.9686, 2.8734,\n",
       "          0.6193, 1.7204],\n",
       "         [7.2496, 1.9971, 9.6366, 1.3895, 7.3527, 3.1098, 4.0482, 0.4020, 9.5900,\n",
       "          9.3712, 8.2028, 8.5781, 2.3687, 7.2434, 6.3210, 5.4506, 6.1030, 3.3510,\n",
       "          2.9441, 6.0768]]),\n",
       " tensor([[3.1279, 0.9928, 9.7187, 0.3075, 0.6357, 0.9825, 2.4352, 1.0459, 8.7313,\n",
       "          9.8539, 7.3765, 4.7880, 9.3671, 3.4423, 3.4985, 4.6177, 4.3857, 1.4117,\n",
       "          3.4184, 4.6062],\n",
       "         [8.8944, 9.0021, 9.7262, 4.6623, 2.0023, 0.7420, 9.4043, 2.8883, 9.2319,\n",
       "          2.1349, 5.3662, 7.3730, 9.9362, 2.9601, 6.6864, 0.2494, 5.4359, 7.5440,\n",
       "          3.6876, 7.1155]]),\n",
       " tensor([[7.5660, 5.7013, 6.9801, 4.4851, 4.2972, 0.0187, 4.9899, 9.6795, 7.4681,\n",
       "          6.4170, 5.7069, 9.5501, 3.0683, 5.1297, 8.7910, 2.2706, 9.0635, 5.9071,\n",
       "          0.0800, 2.6293],\n",
       "         [8.6546, 5.6108, 5.5279, 2.9730, 5.6863, 2.5411, 1.5394, 9.7781, 7.3045,\n",
       "          7.3840, 6.0824, 6.2007, 4.9420, 3.7364, 8.5375, 5.8401, 4.2204, 6.1527,\n",
       "          4.0126, 8.7563]]),\n",
       " tensor([[6.4231, 5.0123, 4.1472, 9.1856, 4.3418, 1.0839, 9.5080, 7.2975, 2.6201,\n",
       "          7.3198, 3.2613, 1.1241, 5.0049, 0.6208, 4.2154, 3.0913, 5.9208, 7.3095,\n",
       "          1.2238, 1.9691],\n",
       "         [0.3000, 7.4633, 6.7994, 6.1985, 1.7273, 7.3642, 9.9322, 9.4940, 6.0239,\n",
       "          1.8040, 9.9522, 2.0858, 0.9993, 3.2238, 4.1133, 3.4362, 8.7107, 1.9128,\n",
       "          1.9421, 6.5249]]),\n",
       " tensor([[5.4882, 5.6633, 0.5092, 0.8696, 4.8484, 0.1203, 8.6890, 1.2002, 8.5378,\n",
       "          5.1071, 1.4944, 9.6763, 4.4811, 1.9836, 4.2185, 7.1243, 8.7105, 0.9961,\n",
       "          6.5660, 8.2052],\n",
       "         [5.3120, 3.4659, 1.8728, 9.5988, 6.0438, 4.9317, 8.4672, 8.4112, 5.3061,\n",
       "          6.7365, 7.8501, 6.1515, 3.2187, 5.1284, 6.8535, 9.2705, 1.0851, 1.5490,\n",
       "          7.5884, 5.6948]]),\n",
       " tensor([[5.2773, 7.1740, 1.2301, 8.0083, 8.0716, 0.3873, 1.1899, 9.7626, 5.6529,\n",
       "          2.9687, 1.2330, 2.6415, 4.2065, 7.7170, 9.3797, 6.9996, 7.8152, 6.2634,\n",
       "          4.7799, 1.3895],\n",
       "         [2.8743, 2.4448, 9.9947, 4.6597, 0.2465, 9.6552, 7.8318, 1.9174, 4.6009,\n",
       "          1.7958, 3.7927, 1.9040, 5.5970, 1.0399, 9.5916, 0.6631, 6.5781, 7.3635,\n",
       "          9.1493, 2.8387]]),\n",
       " tensor([[9.6546, 3.5909, 3.6994, 2.8575, 8.5413, 0.4008, 2.0983, 2.7545, 7.7764,\n",
       "          5.9903, 8.6980, 3.6940, 4.7416, 5.5132, 0.5392, 0.1589, 4.2474, 6.5297,\n",
       "          4.2292, 6.6197],\n",
       "         [9.4132, 1.1517, 2.9006, 6.1542, 4.8106, 2.6679, 0.3620, 9.2846, 7.7936,\n",
       "          7.4772, 5.3844, 2.2307, 3.6179, 2.0424, 4.3055, 1.3845, 0.8474, 0.7569,\n",
       "          1.9621, 8.9645]]),\n",
       " tensor([[9.2560, 8.5848, 2.4772, 6.5946, 3.7761, 4.4583, 2.8444, 4.2166, 9.0947,\n",
       "          9.7443, 9.3481, 7.7493, 7.3077, 7.3593, 4.8083, 6.1836, 9.6043, 9.2241,\n",
       "          3.0546, 9.9692],\n",
       "         [1.8980, 5.2228, 6.7094, 9.6389, 8.4025, 5.5805, 1.9608, 9.4995, 6.5943,\n",
       "          0.2718, 7.2152, 7.3714, 3.3734, 2.4955, 8.4353, 4.1032, 8.9977, 0.1581,\n",
       "          7.5108, 5.4860]]),\n",
       " tensor([[1.5730, 0.2620, 9.8970, 6.7967, 6.5077, 3.0151, 8.8726, 9.4609, 5.6456,\n",
       "          2.4777, 5.6117, 4.3282, 7.9584, 3.1656, 6.1324, 0.1534, 8.9990, 3.7061,\n",
       "          9.1166, 9.6640],\n",
       "         [8.1777, 8.7538, 7.5589, 6.6131, 6.3710, 6.0384, 0.6933, 0.5177, 4.1888,\n",
       "          6.2044, 9.6231, 3.4680, 6.0852, 3.5714, 4.2858, 7.0196, 4.0147, 3.9545,\n",
       "          9.6182, 0.3243]]),\n",
       " tensor([[2.8812, 6.6772, 2.0470, 7.2931, 5.5389, 6.6342, 1.1122, 5.4344, 1.6803,\n",
       "          8.2271, 6.5019, 1.7975, 7.5732, 3.1555, 9.9724, 4.8026, 9.3320, 1.1738,\n",
       "          3.6919, 6.9561],\n",
       "         [7.9337, 7.0928, 6.8058, 1.1288, 7.9341, 5.2476, 3.2879, 1.2015, 0.0658,\n",
       "          4.2699, 6.0334, 9.9378, 5.7251, 9.6254, 4.3270, 9.0553, 3.1369, 2.9456,\n",
       "          4.7181, 8.5194]]),\n",
       " tensor([[6.7210, 0.2701, 8.2566, 8.7094, 4.4090, 9.9468, 8.5001, 0.1130, 7.1024,\n",
       "          5.6184, 0.4728, 2.3855, 9.7395, 9.0688, 4.5153, 5.2315, 6.3448, 1.7610,\n",
       "          4.7432, 8.7623],\n",
       "         [0.1095, 0.6884, 5.1927, 7.1077, 6.8322, 3.2982, 8.0276, 0.7954, 4.1006,\n",
       "          8.5879, 1.0237, 5.3950, 7.0256, 8.7391, 7.1402, 6.6231, 3.4052, 7.3875,\n",
       "          4.9199, 2.4678]]),\n",
       " tensor([[7.9204e+00, 7.1045e+00, 4.4146e+00, 3.4462e+00, 6.9867e+00, 9.4094e+00,\n",
       "          9.0551e+00, 1.3968e+00, 1.0012e-01, 5.3295e+00, 6.4433e+00, 6.0804e+00,\n",
       "          2.3179e+00, 8.7476e-03, 2.8880e+00, 2.2535e+00, 5.7721e+00, 9.1063e+00,\n",
       "          1.4972e+00, 7.0831e+00],\n",
       "         [2.1939e+00, 1.9032e+00, 7.6258e+00, 7.1212e+00, 5.4001e+00, 5.0623e+00,\n",
       "          7.9088e+00, 2.9232e+00, 5.0916e+00, 4.5950e+00, 6.2787e+00, 2.1050e+00,\n",
       "          1.2926e-01, 4.6414e+00, 4.8255e+00, 5.1658e+00, 3.3887e+00, 6.7836e+00,\n",
       "          3.1567e+00, 2.2103e+00]]),\n",
       " tensor([[6.3153, 3.2906, 0.7823, 7.2160, 8.8585, 9.8756, 4.2061, 5.8326, 3.3573,\n",
       "          7.6846, 6.5257, 3.8591, 8.6686, 8.2048, 0.2653, 0.0397, 4.0185, 0.1914,\n",
       "          6.7701, 4.3818],\n",
       "         [6.8428, 4.1253, 0.1187, 7.1347, 7.6777, 0.0376, 3.7480, 5.6785, 1.9421,\n",
       "          1.3975, 8.1672, 8.9373, 2.3578, 7.8061, 9.4168, 9.8629, 3.6925, 4.7295,\n",
       "          6.2113, 0.3834]]),\n",
       " tensor([[7.5427, 5.4582, 2.7736, 1.4569, 9.6743, 8.9791, 5.5605, 9.5469, 3.4002,\n",
       "          0.4457, 9.8047, 8.1348, 4.1953, 8.8344, 9.8747, 5.2255, 4.9844, 9.6732,\n",
       "          1.6678, 2.3002],\n",
       "         [3.6971, 4.2040, 5.4385, 4.9990, 6.5778, 2.8717, 0.8634, 1.3731, 6.5962,\n",
       "          9.6358, 7.9074, 4.0875, 2.4466, 2.3850, 9.9199, 6.1127, 7.0477, 9.9526,\n",
       "          9.2098, 8.2638]]),\n",
       " tensor([[3.0606, 8.8952, 7.8645, 6.4176, 5.9094, 0.3168, 5.1478, 5.0631, 5.9022,\n",
       "          6.5154, 8.4239, 7.2982, 6.8367, 3.9987, 0.1084, 3.2024, 3.1969, 9.5496,\n",
       "          1.8495, 7.9229],\n",
       "         [5.4233, 0.3611, 2.3850, 7.8097, 2.9918, 5.9736, 5.0328, 3.5740, 3.6132,\n",
       "          3.4828, 9.2268, 3.0759, 4.5595, 0.3597, 4.7050, 2.5800, 3.1304, 3.3590,\n",
       "          8.1500, 2.8060]]),\n",
       " tensor([[9.1456, 9.4545, 6.7323, 3.6088, 5.9333, 1.5982, 2.1770, 1.6336, 1.5357,\n",
       "          0.8923, 2.5472, 7.4317, 6.9450, 5.1118, 2.7814, 5.4809, 6.7183, 8.7886,\n",
       "          1.5653, 0.1080],\n",
       "         [6.1669, 6.7714, 4.7662, 8.9297, 4.2618, 3.6848, 5.5017, 0.5423, 4.3262,\n",
       "          1.3235, 9.9091, 5.0961, 8.9343, 9.7946, 6.5910, 0.4184, 2.6111, 3.8199,\n",
       "          9.8908, 4.3845]]),\n",
       " tensor([[4.4064, 8.4973, 7.3859, 1.6231, 8.3065, 6.6032, 6.6771, 3.2425, 5.5301,\n",
       "          6.5277, 4.5747, 0.9701, 5.3556, 1.7691, 8.2673, 7.9419, 1.5224, 2.9994,\n",
       "          4.7545, 6.3664],\n",
       "         [4.6971, 5.8656, 7.1008, 6.6856, 4.7992, 6.6470, 3.4848, 3.1427, 8.8242,\n",
       "          5.9048, 3.1862, 0.3122, 1.0115, 5.1220, 8.4127, 9.6973, 0.6360, 3.6407,\n",
       "          6.6658, 7.6276]]),\n",
       " tensor([[6.7688, 0.3275, 4.0836, 0.4806, 6.9442, 0.8083, 9.0492, 5.9745, 9.9512,\n",
       "          7.3561, 3.5450, 3.5950, 7.0374, 9.5713, 5.4838, 0.9859, 9.4194, 1.0800,\n",
       "          6.6123, 9.3578],\n",
       "         [7.6895, 6.8962, 8.7111, 5.5347, 5.6410, 8.4359, 7.6951, 7.4038, 2.9634,\n",
       "          4.7324, 0.5504, 8.3295, 3.2955, 5.7607, 2.5959, 2.1626, 9.9947, 0.4690,\n",
       "          1.1947, 4.0762]]),\n",
       " tensor([[9.7812, 1.6634, 5.2742, 0.0228, 2.7843, 8.0746, 3.3356, 6.5749, 0.2274,\n",
       "          6.0536, 4.6521, 5.3991, 6.0280, 9.6667, 5.3251, 7.7233, 8.2690, 8.6207,\n",
       "          1.2763, 3.1164],\n",
       "         [2.8676, 0.8140, 4.2806, 3.5555, 1.6653, 8.3599, 4.8148, 9.7842, 9.4819,\n",
       "          0.8328, 6.7040, 0.4484, 4.5610, 2.9782, 1.6260, 6.4019, 9.0168, 3.5139,\n",
       "          0.4207, 2.4999]]),\n",
       " tensor([[2.7227, 1.7552, 4.4834, 8.4499, 1.5722, 4.8749, 4.9691, 1.3147, 2.6128,\n",
       "          5.5489, 5.8187, 3.2575, 0.2778, 7.6021, 5.0795, 8.6603, 6.6107, 6.3243,\n",
       "          2.3984, 7.4730],\n",
       "         [3.0073, 0.6520, 4.2213, 1.8084, 6.1318, 0.7546, 1.1060, 9.9789, 7.5785,\n",
       "          1.1077, 0.2303, 0.1262, 4.6021, 3.0476, 8.3369, 4.4702, 8.3756, 5.3984,\n",
       "          9.4616, 7.5166]]),\n",
       " tensor([[1.9844, 3.0308, 6.3462, 8.2724, 0.6630, 4.1350, 1.9587, 8.1061, 2.5129,\n",
       "          9.0345, 7.9860, 9.8802, 6.1057, 6.0783, 1.1468, 5.5294, 8.1332, 9.8216,\n",
       "          3.1740, 8.9536],\n",
       "         [1.4772, 9.5364, 4.0880, 4.6419, 3.5767, 5.8891, 3.6016, 8.6465, 9.2079,\n",
       "          7.5127, 5.3514, 0.9389, 2.3706, 5.0846, 2.0727, 5.8034, 3.7604, 9.7749,\n",
       "          7.0000, 9.5319]]),\n",
       " tensor([[9.9207, 7.4614, 7.4344, 5.7582, 2.2047, 8.9957, 1.0480, 2.0914, 6.5461,\n",
       "          9.9192, 1.0422, 4.1462, 3.9133, 0.4158, 3.2180, 0.2456, 0.2339, 9.3594,\n",
       "          9.4726, 6.3377],\n",
       "         [5.7672, 9.8954, 1.6247, 0.2584, 6.3545, 9.1884, 6.0751, 6.0774, 5.0000,\n",
       "          5.5720, 6.4436, 9.6749, 8.6881, 9.3244, 6.7324, 3.9333, 5.3785, 1.5718,\n",
       "          1.3128, 5.9543]]),\n",
       " tensor([[1.7965, 0.1819, 6.9404, 9.2995, 4.5665, 4.3693, 3.0196, 9.6267, 6.4663,\n",
       "          1.2515, 1.3318, 2.6519, 8.0444, 4.8875, 2.7384, 6.5320, 8.9772, 8.6098,\n",
       "          1.9216, 5.9042],\n",
       "         [8.3387, 3.4202, 6.7184, 6.9173, 5.1042, 2.5193, 9.9506, 4.8688, 0.4244,\n",
       "          5.5584, 9.6563, 5.4337, 0.8680, 3.7451, 0.8915, 5.5910, 6.3958, 6.2941,\n",
       "          0.6015, 6.9650]]),\n",
       " tensor([[4.3971, 6.4015, 9.7973, 5.7570, 4.9606, 6.1422, 7.5184, 0.8736, 5.1474,\n",
       "          2.5201, 1.4176, 0.1804, 7.5382, 6.0211, 9.3290, 7.5374, 2.2913, 9.9465,\n",
       "          5.9112, 0.1366],\n",
       "         [5.0623, 6.5899, 1.6732, 8.4552, 7.6883, 9.3716, 5.9582, 6.9460, 4.3116,\n",
       "          8.1483, 8.6424, 2.8712, 1.6204, 4.4830, 1.4620, 3.0576, 4.8291, 0.5691,\n",
       "          3.9699, 3.4015]]),\n",
       " tensor([[7.1456, 4.9303, 4.4936, 8.6702, 6.4196, 1.2399, 9.5785, 0.4540, 1.5531,\n",
       "          2.5569, 4.5240, 9.6720, 4.2131, 4.2683, 8.3535, 7.9416, 8.2614, 6.5489,\n",
       "          8.1262, 1.2661],\n",
       "         [8.3072, 0.7495, 3.1321, 0.3757, 0.1085, 4.2810, 6.0663, 3.3594, 4.8179,\n",
       "          8.0561, 3.7671, 7.1648, 7.6826, 4.3372, 5.8859, 5.8838, 4.2417, 3.4407,\n",
       "          8.6506, 6.2812]]),\n",
       " tensor([[4.6348, 8.1301, 9.4875, 1.0008, 6.7735, 1.1122, 5.7520, 9.6936, 3.3748,\n",
       "          7.3772, 3.4272, 6.4985, 5.0263, 0.4188, 0.0123, 1.4676, 0.1204, 1.3260,\n",
       "          2.0671, 7.1010],\n",
       "         [9.0147, 3.3057, 6.3245, 9.1707, 7.3970, 4.8299, 0.9426, 4.6645, 2.6007,\n",
       "          2.2963, 2.5005, 4.5615, 8.7129, 2.1970, 3.1285, 3.7974, 5.0744, 3.1393,\n",
       "          7.9398, 6.5956]]),\n",
       " tensor([[1.9031, 0.3850, 9.7636, 1.0246, 7.6927, 4.1000, 3.8601, 1.7631, 4.3563,\n",
       "          8.5065, 4.1437, 2.0571, 3.6867, 2.9322, 5.1866, 4.2490, 9.8358, 9.2647,\n",
       "          9.0393, 6.9312],\n",
       "         [1.7699, 5.4798, 3.0379, 7.6141, 1.9596, 9.6313, 3.7260, 1.1873, 4.5338,\n",
       "          8.2969, 4.5723, 4.6932, 3.9000, 7.6535, 9.8471, 6.6921, 4.4041, 9.3714,\n",
       "          3.9738, 7.6415]]),\n",
       " tensor([[8.7047, 7.4453, 0.8243, 6.2991, 3.0051, 4.4577, 5.2935, 3.2277, 6.6202,\n",
       "          8.4459, 6.9562, 1.6003, 3.0304, 0.4548, 1.6907, 3.1306, 0.3693, 1.8736,\n",
       "          8.1090, 8.5442],\n",
       "         [9.1212, 0.8692, 4.1768, 6.9813, 7.7078, 8.6209, 4.7136, 7.1534, 9.8593,\n",
       "          8.8240, 1.2598, 5.8719, 9.0798, 7.5301, 3.0416, 4.1383, 3.7061, 0.3361,\n",
       "          0.5896, 9.5351]]),\n",
       " tensor([[9.8924e+00, 7.4583e+00, 4.5801e+00, 6.6182e+00, 6.5774e+00, 2.0046e-01,\n",
       "          4.3052e-03, 4.1521e+00, 4.8482e-02, 7.1626e+00, 6.3117e+00, 2.7081e+00,\n",
       "          8.7733e+00, 4.3938e-01, 6.3950e+00, 5.6345e+00, 5.3864e+00, 3.8307e+00,\n",
       "          2.1900e+00, 5.0531e+00],\n",
       "         [7.1033e-01, 6.1031e+00, 1.8864e+00, 4.0637e+00, 2.8749e+00, 2.9229e+00,\n",
       "          2.0020e+00, 1.3042e+00, 2.3407e+00, 8.9021e-01, 6.1721e+00, 5.7596e+00,\n",
       "          2.0133e+00, 5.9571e-02, 1.8728e+00, 1.2674e+00, 7.5707e+00, 7.1558e+00,\n",
       "          1.7241e+00, 4.2499e+00]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_20_dataset.data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(sample_solution, USE_CUDA=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample_solution seq_len of [batch_size]\n",
    "    \"\"\"\n",
    "    batch_size = sample_solution[0].size(0)\n",
    "    n = len(sample_solution)\n",
    "    tour_len = Variable(torch.zeros([batch_size]))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        tour_len = tour_len.cuda()\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        tour_len += torch.norm(sample_solution[i] - sample_solution[i + 1], dim=1)\n",
    "    \n",
    "    tour_len += torch.norm(sample_solution[n - 1] - sample_solution[0], dim=1)\n",
    "\n",
    "    return tour_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, use_tanh=False, C=10, name='Bahdanau', use_cuda=USE_CUDA):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.use_tanh = use_tanh\n",
    "        self.C = C\n",
    "        self.name = name\n",
    "        \n",
    "        if name == 'Bahdanau':\n",
    "            self.W_query = nn.Linear(hidden_size, hidden_size)\n",
    "            self.W_ref   = nn.Conv1d(hidden_size, hidden_size, 1, 1)\n",
    "\n",
    "            V = torch.FloatTensor(hidden_size)\n",
    "            if use_cuda:\n",
    "                V = V.cuda()  \n",
    "            self.V = nn.Parameter(V)\n",
    "            self.V.data.uniform_(-(1. / math.sqrt(hidden_size)) , 1. / math.sqrt(hidden_size))\n",
    "            \n",
    "        \n",
    "    def forward(self, query, ref):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            query: [batch_size x hidden_size]\n",
    "            ref:   ]batch_size x seq_len x hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = ref.size(0)\n",
    "        seq_len    = ref.size(1)\n",
    "        \n",
    "        if self.name == 'Bahdanau':\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "            query = self.W_query(query).unsqueeze(2)  # [batch_size x hidden_size x 1]\n",
    "            ref   = self.W_ref(ref)  # [batch_size x hidden_size x seq_len] \n",
    "            expanded_query = query.repeat(1, 1, seq_len) # [batch_size x hidden_size x seq_len]\n",
    "            V = self.V.unsqueeze(0).unsqueeze(0).repeat(batch_size, 1, 1) # [batch_size x 1 x hidden_size]\n",
    "            logits = torch.bmm(V, F.tanh(expanded_query + ref)).squeeze(1)\n",
    "            \n",
    "        elif self.name == 'Dot':\n",
    "            query  = query.unsqueeze(2)\n",
    "            logits = torch.bmm(ref, query).squeeze(2) #[batch_size x seq_len x 1]\n",
    "            ref = ref.permute(0, 2, 1)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if self.use_tanh:\n",
    "            logits = self.C * F.tanh(logits)\n",
    "        else:\n",
    "            logits = logits  \n",
    "        return ref, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, use_cuda=USE_CUDA):\n",
    "        super(GraphEmbedding, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.embedding = nn.Parameter(torch.FloatTensor(input_size, embedding_size)) \n",
    "        self.embedding.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        embedding = self.embedding.repeat(batch_size, 1, 1)  \n",
    "        embedded = []\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        for i in range(seq_len):\n",
    "            embedded.append(torch.bmm(inputs[:, :, :, i].float(), embedding))\n",
    "        embedded = torch.cat(embedded, 1)\n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerNet(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(PointerNet, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.n_glimpses     = n_glimpses\n",
    "        self.seq_len        = seq_len\n",
    "        self.use_cuda       = use_cuda\n",
    "        \n",
    "        \n",
    "        self.embedding = GraphEmbedding(2, embedding_size, use_cuda=use_cuda)\n",
    "        self.encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.pointer = Attention(hidden_size, use_tanh=use_tanh, C=tanh_exploration, name=attention, use_cuda=use_cuda)\n",
    "        self.glimpse = Attention(hidden_size, use_tanh=False, name=attention, use_cuda=use_cuda)\n",
    "        \n",
    "        self.decoder_start_input = nn.Parameter(torch.FloatTensor(embedding_size))\n",
    "        self.decoder_start_input.data.uniform_(-(1. / math.sqrt(embedding_size)), 1. / math.sqrt(embedding_size))\n",
    "        \n",
    "    def apply_mask_to_logits(self, logits, mask, idxs): \n",
    "        batch_size = logits.size(0)\n",
    "        clone_mask = mask.clone()\n",
    "\n",
    "        if idxs is not None:\n",
    "            clone_mask[[i for i in range(batch_size)], idxs.data] = 1\n",
    "            logits[clone_mask] = -np.inf\n",
    "        return logits, clone_mask\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: [batch_size x 1 x sourceL]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        seq_len    = inputs.size(2)\n",
    "        assert seq_len == self.seq_len\n",
    "        \n",
    "        embedded = self.embedding(inputs)\n",
    "        encoder_outputs, (hidden, context) = self.encoder(embedded)\n",
    "        \n",
    "        \n",
    "        prev_probs = []\n",
    "        prev_idxs = []\n",
    "        mask = torch.zeros(batch_size, seq_len).byte()\n",
    "        if self.use_cuda:\n",
    "            mask = mask.cuda()\n",
    "            \n",
    "        idxs = None\n",
    "       \n",
    "        decoder_input = self.decoder_start_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            \n",
    "            \n",
    "            _, (hidden, context) = self.decoder(decoder_input.unsqueeze(1), (hidden, context))\n",
    "            \n",
    "            query = hidden.squeeze(0)\n",
    "            for i in range(self.n_glimpses):\n",
    "                ref, logits = self.glimpse(query, encoder_outputs)\n",
    "                logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "                query = torch.bmm(ref, F.softmax(logits).unsqueeze(2)).squeeze(2) \n",
    "                \n",
    "                \n",
    "            _, logits = self.pointer(query, encoder_outputs)\n",
    "            logits, mask = self.apply_mask_to_logits(logits, mask, idxs)\n",
    "            probs = F.softmax(logits)\n",
    "            \n",
    "            \n",
    "            idxs = probs.multinomial().squeeze(1)\n",
    "            for old_idxs in prev_idxs:\n",
    "                if old_idxs.eq(idxs).data.any():\n",
    "                    print (seq_len)\n",
    "                    print(' RESAMPLE!')\n",
    "                    idxs = probs.multinomial().squeeze(1)\n",
    "                    break\n",
    "            decoder_input = embedded[[i for i in range(batch_size)], idxs.data, :] \n",
    "            \n",
    "            prev_probs.append(probs)\n",
    "            prev_idxs.append(idxs)\n",
    "            \n",
    "        return prev_probs, prev_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialRL(nn.Module):\n",
    "    def __init__(self, \n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            seq_len,\n",
    "            n_glimpses,\n",
    "            tanh_exploration,\n",
    "            use_tanh,\n",
    "            reward,\n",
    "            attention,\n",
    "            use_cuda=USE_CUDA):\n",
    "        super(CombinatorialRL, self).__init__()\n",
    "        self.reward = reward\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.actor = PointerNet(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                seq_len,\n",
    "                n_glimpses,\n",
    "                tanh_exploration,\n",
    "                use_tanh,\n",
    "                attention,\n",
    "                use_cuda)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [batch_size, input_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        input_size = inputs.size(1)\n",
    "        seq_len    = inputs.size(2)\n",
    "        \n",
    "        probs, action_idxs = self.actor(inputs)\n",
    "       \n",
    "        actions = []\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        for action_id in action_idxs:\n",
    "            actions.append(inputs[[x for x in range(batch_size)], action_id.data, :])\n",
    "\n",
    "            \n",
    "        action_probs = []    \n",
    "        for prob, action_id in zip(probs, action_idxs):\n",
    "            action_probs.append(prob[[x for x in range(batch_size)], action_id.data])\n",
    "\n",
    "        R = self.reward(actions, self.use_cuda)\n",
    "        \n",
    "        return R, action_probs, actions, action_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size    = 128\n",
    "n_glimpses = 1\n",
    "tanh_exploration = 10\n",
    "use_tanh = True\n",
    "\n",
    "beta = 0.9\n",
    "max_grad_norm = 2.\n",
    "\n",
    "tsp_20_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        20,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        reward,\n",
    "        attention=\"Dot\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "tsp_50_model = CombinatorialRL(\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        50,\n",
    "        n_glimpses, \n",
    "        tanh_exploration,\n",
    "        use_tanh,\n",
    "        reward,\n",
    "        attention=\"Bahdanau\",\n",
    "        use_cuda=USE_CUDA)\n",
    "\n",
    "if USE_CUDA:\n",
    "    tsp_20_model = tsp_20_model.cuda()\n",
    "    tsp_50_model = tsp_50_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, model, train_dataset, val_dataset, batch_size=128, threshold=None, max_grad_norm=2.):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset   = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "        self.val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        self.actor_optim   = optim.Adam(model.actor.parameters(), lr=1e-4)\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "        self.train_tour = []\n",
    "        self.val_tour   = []\n",
    "        \n",
    "        self.epochs = 0\n",
    "    \n",
    "    def train_and_validate(self, n_epochs):\n",
    "        critic_exp_mvg_avg = torch.zeros(1)\n",
    "        if USE_CUDA: \n",
    "            critic_exp_mvg_avg = critic_exp_mvg_avg.cuda()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_id, sample_batch in enumerate(self.train_loader):\n",
    "                self.model.train()\n",
    "\n",
    "                inputs = Variable(sample_batch)\n",
    "                inputs = inputs.cuda()\n",
    "\n",
    "                R, probs, actions, actions_idxs = self.model(inputs)\n",
    "\n",
    "                if batch_id == 0:\n",
    "                    critic_exp_mvg_avg = R.mean()\n",
    "                else:\n",
    "                    critic_exp_mvg_avg = (critic_exp_mvg_avg * beta) + ((1. - beta) * R.mean())\n",
    "\n",
    "\n",
    "                advantage = R - critic_exp_mvg_avg\n",
    "\n",
    "                logprobs = 0\n",
    "                for prob in probs: \n",
    "                    logprob = torch.log(prob)\n",
    "                    logprobs += logprob\n",
    "                logprobs[logprobs < -1000] = 0.  \n",
    "\n",
    "                reinforce = advantage * logprobs\n",
    "                actor_loss = reinforce.mean()\n",
    "\n",
    "                self.actor_optim.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm(self.model.actor.parameters(),\n",
    "                                    float(self.max_grad_norm), norm_type=2)\n",
    "\n",
    "                self.actor_optim.step()\n",
    "\n",
    "                critic_exp_mvg_avg = critic_exp_mvg_avg.detach()\n",
    "\n",
    "                self.train_tour.append(R.mean().data[0])\n",
    "\n",
    "                if batch_id % 10 == 0:\n",
    "                    self.plot(self.epochs)\n",
    "\n",
    "                if batch_id % 100 == 0:    \n",
    "\n",
    "                    self.model.eval()\n",
    "                    for val_batch in self.val_loader:\n",
    "                        inputs = Variable(val_batch)\n",
    "                        inputs = inputs.cuda()\n",
    "\n",
    "                        R, probs, actions, actions_idxs = self.model(inputs)\n",
    "                        self.val_tour.append(R.mean().data[0])\n",
    "\n",
    "            if self.threshold and self.train_tour[-1] < self.threshold:\n",
    "                print (\"EARLY STOPPAGE!\")\n",
    "                break\n",
    "                \n",
    "            self.epochs += 1\n",
    "                \n",
    "    def plot(self, epoch):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train tour length: epoch %s reward %s' % (epoch, self.train_tour[-1] if len(self.train_tour) else 'collecting'))\n",
    "        plt.plot(self.train_tour)\n",
    "        plt.grid()\n",
    "        plt.subplot(132)\n",
    "        plt.title('val tour length: epoch %s reward %s' % (epoch, self.val_tour[-1] if len(self.val_tour) else 'collecting'))\n",
    "        plt.plot(self.val_tour)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_20_train = TrainModel(tsp_20_model, \n",
    "                        train_20_dataset, \n",
    "                        val_20_dataset, \n",
    "                        threshold=3.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TSPDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 30286) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 30286) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tsp_20_train\u001b[39m.\u001b[39;49mtrain_and_validate(\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb 单元格 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     critic_exp_mvg_avg \u001b[39m=\u001b[39m critic_exp_mvg_avg\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_id, sample_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/MissionPlanning/MPS/nco.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         inputs \u001b[39m=\u001b[39m Variable(sample_batch)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{\u001b[39;00mpids_str\u001b[39m}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 30286) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "tsp_20_train.train_and_validate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_50_train = TrainModel(tsp_50_model, \n",
    "#                             train_50_dataset, \n",
    "#                             val_50_dataset, \n",
    "#                             threshold=6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_50_train.train_and_validate(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl4co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
