{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Environment: Creating and Modeling\n",
    "<!-- \n",
    "<a href=\"https://colab.research.google.com/github/kaist-silab/rl4co/blob/main/notebooks/1-quickstart.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "\n",
    "[**Documentation**](https://rl4co.readthedocs.io/) |  [**Getting Started**](https://github.com/kaist-silab/rl4co/tree/main#getting-started) | [**Usage**](https://github.com/kaist-silab/rl4co/tree/main#usage) | [**Contributing**](#contributing) | [**Paper**](https://arxiv.org/abs/2306.17100) | [**Citation**](#cite-us) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to extend RL4CO to solve new problems from zero to hero! 🚀\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/kaist-silab/rl4co/blob/main/notebooks/tutorials/2-solving-new-problem.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [Environment](#environment-creation)\n",
    "2. [Modeling](#modeling)\n",
    "3. [Training](#training-our-model)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: MDPDP\n",
    "Let us consider a new complex problem: the _Open Multi-Depot Pickup and Delivery Problem (MDPDP)_. \n",
    "- **Objective**: find set of routes for a fleet of vehicles to pickup and deliver a set of orders such that the total routes are minimized. Vehicles start from different depots and the problem is _open_ since they do not need to return to the depot.\n",
    "- **Constraints**:\n",
    "    - Maximum number of vehicles (i.e. agents) is fixed\n",
    "    - Each vehicle has a maximum capacity\n",
    "    - Pickup and delivery pairs have to be served by the same vehicle with a precendence constraint (no pickup before delivery)\n",
    "\n",
    "The MDPDP is a complex, realistic problem that can be solved with RL4CO. For instance, this problem can be found in the context of ride-sharing, where a fleet of vehicles (e.g. taxis) have to pickup and deliver passengers to their destinations or in the context of food delivery, where a fleet of vehicles (e.g. riders) have to pickup and deliver orders to customers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rl4co in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (0.2.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (2.1.0)\n",
      "Requirement already satisfied: torchrl>=0.1.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (0.2.0)\n",
      "Requirement already satisfied: tensordict>=0.1.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (0.2.0)\n",
      "Requirement already satisfied: lightning>=2.0.5 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (2.0.9.post0)\n",
      "Requirement already satisfied: hydra-core in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (1.3.2)\n",
      "Requirement already satisfied: hydra-colorlog in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (1.2.0)\n",
      "Requirement already satisfied: omegaconf in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (2.3.0)\n",
      "Requirement already satisfied: pyrootutils in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (1.0.4)\n",
      "Requirement already satisfied: rich in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (13.6.0)\n",
      "Requirement already satisfied: einops in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (0.7.0)\n",
      "Requirement already satisfied: wandb in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (0.15.12)\n",
      "Requirement already satisfied: matplotlib in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (3.8.0)\n",
      "Requirement already satisfied: scipy in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (1.11.3)\n",
      "Requirement already satisfied: robust-downloader in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rl4co) (0.0.1)\n",
      "Requirement already satisfied: Jinja2<5.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (6.0.1)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.3.0)\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (4.12.2)\n",
      "Requirement already satisfied: click<10.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (8.1.7)\n",
      "Requirement already satisfied: croniter<1.5.0,>=1.3.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.4.1)\n",
      "Requirement already satisfied: dateutils<2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (6.6.0)\n",
      "Requirement already satisfied: fastapi<2.0,>=0.92.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.103.2)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (2023.9.2)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (3.1.3)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.38 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.5.39)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (23.2)\n",
      "Requirement already satisfied: psutil<7.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (5.9.5)\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (2.1.1)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.0.6)\n",
      "Requirement already satisfied: requests<4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (2.28.2)\n",
      "Requirement already satisfied: starlette in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.27.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.3.0)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (4.66.1)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (5.11.2)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (4.8.0)\n",
      "Requirement already satisfied: urllib3<4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.26.18)\n",
      "Requirement already satisfied: uvicorn<2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (0.23.2)\n",
      "Requirement already satisfied: websocket-client<3.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (1.5.3)\n",
      "Requirement already satisfied: websockets<13.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (10.4)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning>=2.0.5->rl4co) (2.0.9.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rich->rl4co) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from rich->rl4co) (2.16.1)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from tensordict>=0.1.1->rl4co) (2.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from torch>=2.0.0->rl4co) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from torch>=2.0.0->rl4co) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from torch>=2.0.0->rl4co) (2.8.8)\n",
      "Requirement already satisfied: colorlog in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from hydra-colorlog->rl4co) (6.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from hydra-core->rl4co) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from matplotlib->rl4co) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from pyrootutils->rl4co) (1.0.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (3.1.37)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (1.31.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from wandb->rl4co) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/hexh/.local/lib/python3.10/site-packages (from wandb->rl4co) (4.21.5)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning>=2.0.5->rl4co) (2.8.19.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning>=2.0.5->rl4co) (2.5)\n",
      "Requirement already satisfied: pytz in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from dateutils<2.0->lightning>=2.0.5->rl4co) (2023.3.post1)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from deepdiff<8.0,>=5.7.0->lightning>=2.0.5->rl4co) (4.1.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->rl4co) (1.16.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from fastapi<2.0,>=0.92.0->lightning>=2.0.5->rl4co) (3.7.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (3.8.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->rl4co) (4.0.10)\n",
      "Requirement already satisfied: blessed>=1.19.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.5->rl4co) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.5->rl4co) (1.0.4)\n",
      "Requirement already satisfied: readchar>=3.0.6 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.5->rl4co) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from Jinja2<5.0->lightning>=2.0.5->rl4co) (2.1.3)\n",
      "Requirement already satisfied: pyjwt in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from lightning-cloud>=0.5.38->lightning>=2.0.5->rl4co) (2.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->rl4co) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from pydantic<2.2.0,>=1.7.4->lightning>=2.0.5->rl4co) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from pydantic<2.2.0,>=1.7.4->lightning>=2.0.5->rl4co) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from requests<4.0->lightning>=2.0.5->rl4co) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from requests<4.0->lightning>=2.0.5->rl4co) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from requests<4.0->lightning>=2.0.5->rl4co) (2023.7.22)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning>=2.0.5->rl4co) (2.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from uvicorn<2.0->lightning>=2.0.5->rl4co) (0.14.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from sympy->torch>=2.0.0->rl4co) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning>=2.0.5->rl4co) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning>=2.0.5->rl4co) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning>=2.0.5->rl4co) (1.1.3)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.5->rl4co) (0.2.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->rl4co) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the following line to install the package from PyPI\n",
    "## You may need to restart the runtime in Colab after this\n",
    "## Remember to choose a GPU runtime for faster training!\n",
    "\n",
    "%pip install rl4co"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.append(2*\"../\")\n",
    "\n",
    "from typing import Optional\n",
    "from einops import rearrange\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tensordict.tensordict import TensorDict\n",
    "from torchrl.data import (\n",
    "    BoundedTensorSpec,\n",
    "    CompositeSpec,\n",
    "    UnboundedContinuousTensorSpec,\n",
    "    UnboundedDiscreteTensorSpec,\n",
    ")\n",
    "\n",
    "from rl4co.envs.common.base import RL4COEnvBase\n",
    "from rl4co.utils.ops import gather_by_index, get_tour_length\n",
    "from rl4co.models.nn.utils import rollout, random_policy\n",
    "from rl4co.models.zoo import AttentionModel, AutoregressivePolicy\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will base environment creation on the `RL4COEnvBase` class, which is based on [TorchRL](https://github.com/pytorch/rl):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset\n",
    "\n",
    "The `_reset` function is used to initialize the environment to an initial state. It returns a TensorDict of the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset(\n",
    "    self, td: Optional[TensorDict] = None, batch_size: Optional[int] = None\n",
    ") -> TensorDict:\n",
    "    if batch_size is None:\n",
    "        batch_size = self.batch_size if td is None else td.batch_size\n",
    "    \n",
    "    # Data generation: if not provided, generate a new batch of data\n",
    "    if td is None or td.is_empty():\n",
    "        td = self.generate_data(batch_size=batch_size)\n",
    "\n",
    "    self.device = td.device\n",
    "\n",
    "    td_reset = TensorDict(\n",
    "        {\n",
    "            \"pickup_locs\": td[\"pickup_locs\"],\n",
    "            \"vehicle_locs\": td[\"vehicle_locs\"],\n",
    "            \"pickup_visited\": torch.zeros(\n",
    "                *td[\"pickup_locs\"].shape[:-1], dtype=torch.bool, device=td.device\n",
    "            ),\n",
    "            \"i\": torch.zeros(batch_size, dtype=torch.int64, device=td.device),\n",
    "            \"current_vehicle_idx\": torch.zeros(\n",
    "                *batch_size, dtype=torch.long, device=td.device\n",
    "            ),  # used to denote vehicle index\n",
    "            \"current_vehicle_loads\": torch.zeros(\n",
    "                *batch_size, dtype=torch.int64, device=td.device\n",
    "            ),  # used to denote current vehicle loads\n",
    "            \"current_vehicle_max_loads\": torch.zeros(\n",
    "                *batch_size, dtype=torch.int64, device=td.device\n",
    "            ),  # used to denote the maximal vehicle loads from the beginning\n",
    "            \"current_vehicle_pickup_visited\": torch.zeros(\n",
    "                *td[\"pickup_locs\"].shape[:-1], 1, dtype=torch.bool, device=td.device\n",
    "            ),  # used to denote whether the pickup is visited by the current vehicle\n",
    "        },\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Compute action mask: mask out actions that are not allowed (e.g., pickup before delivery)\n",
    "    td_reset.set(\"action_mask\", self.get_action_mask(td_reset))\n",
    "    return td_reset    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step\n",
    "\n",
    "Environment `_step`: this defines the state update of the TSP problem gived a TensorDict (td in the code) of the current state and the action to take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _step(self, td: TensorDict) -> TensorDict:\n",
    "    # action: [batch_size, (pickups | deliveries | vehicles)]\n",
    "    selected = td[\"action\"]\n",
    "\n",
    "    # The number of orders is set based on the number of vehicles and the capacity\n",
    "    num_orders = self.num_vehicles * self.capacity\n",
    "\n",
    "    # Identify the action type\n",
    "    is_pickup = selected < num_orders  # bool mask -- [batch]\n",
    "    is_vehicle = selected >= num_orders \n",
    "\n",
    "    selected_pickups = selected[is_pickup] \n",
    "\n",
    "    # ====  Pickup status update ====\n",
    "    td[\"pickup_visited\"][is_pickup, selected_pickups] = True\n",
    "\n",
    "    # Update current load\n",
    "    td[\"current_vehicle_loads\"][is_pickup] += 1\n",
    "\n",
    "    # Update history of pickup visited by the current vehicle\n",
    "    td[\"current_vehicle_max_loads\"][is_pickup] += 1\n",
    "    td[\"current_vehicle_max_loads\"][is_pickup].clamp_(max=self.capacity)\n",
    "\n",
    "    # ====  Vehicle status update ====\n",
    "    # Increment vehicle idx counter\n",
    "    if td[\"i\"][0] > 0:\n",
    "        td[\"current_vehicle_idx\"][is_vehicle] += 1\n",
    "        td[\"current_vehicle_idx\"][is_vehicle].clamp_(max=self.num_vehicles)\n",
    "    # Initialize vehicle load and max loads\n",
    "    td[\"current_vehicle_loads\"][is_vehicle] = 0\n",
    "    td[\"current_vehicle_max_loads\"][is_vehicle] = 0\n",
    "\n",
    "    done = td[\"pickup_visited\"].all(dim=-1) \n",
    "    # The reward is calculated outside via get_reward for efficiency, so we set it to -inf here\n",
    "    reward = torch.ones_like(done) * float(\"-inf\")\n",
    "\n",
    "    # Reti\n",
    "    td_step = TensorDict(\n",
    "        {\n",
    "            \"next\": {\n",
    "                \"pickup_locs\": td[\"pickup_locs\"],\n",
    "                \"vehicle_locs\": td[\"vehicle_locs\"],\n",
    "                \"pickup_visited\": td[\"pickup_visited\"],\n",
    "                \"i\": td[\"i\"] + 1,\n",
    "                \"current_vehicle_idx\": td[\"current_vehicle_idx\"],\n",
    "                \"current_vehicle_loads\": td[\"current_vehicle_loads\"],\n",
    "                \"current_vehicle_max_loads\": td[\"current_vehicle_max_loads\"],\n",
    "                \"current_vehicle_pickup_visited\": td[\n",
    "                    \"current_vehicle_pickup_visited\"\n",
    "                ],\n",
    "                \"current_node\": selected,\n",
    "                \"done\": done,\n",
    "                \"reward\": reward,\n",
    "            },\n",
    "        },\n",
    "        td.shape,\n",
    "    )\n",
    "    td_step[\"next\"].set(\"action_mask\", self.get_action_mask(td_step[\"next\"]))\n",
    "    return td_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Mask\n",
    "\n",
    "The `get_action_mask` function ensured that we only selected actions that were valid for the current state. This is important because we don't want to select actions that are invalid - such as, we cannot deliver a package if we don't have one or visit a location that we have already visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_mask(self, td: TensorDict) -> torch.Tensor:\n",
    "    # At the first decoding step, policy is allowed to select the first vehicle only.\n",
    "    if td[\"i\"][0] == 0:\n",
    "\n",
    "        total_nodes = self.num_vehicles * self.capacity  + self.num_vehicles\n",
    "\n",
    "        action_mask = torch.zeros(\n",
    "            *td.batch_size,\n",
    "            total_nodes,\n",
    "            dtype=torch.bool,\n",
    "            device=td.device,\n",
    "        )\n",
    "        action_mask[:, self.num_vehicles * self.capacity * 2] = True\n",
    "        return action_mask\n",
    "\n",
    "    # Handling pickup action mask\n",
    "    pickup_action_mask = ~td[\"pickup_visited\"]\n",
    "    pickup_action_mask[td[\"current_vehicle_max_loads\"] == self.capacity] = False\n",
    "\n",
    "    # If current vehicle carries \"capacity\" loads, it can only deliver\n",
    "    pickup_action_mask[td[\"current_vehicle_loads\"] >= self.capacity] = False\n",
    "\n",
    "    # Handling vehicle action mask\n",
    "    # vehicle can be selected only if all scheduled deliveries are delivered\n",
    "    # selecting vehicle indicates the end of the current vehicle's tour\n",
    "    pd_action_mask = torch.cat([pickup_action_mask], dim=-1)\n",
    "    # Vehicle action mask becomes true only when the current vehicle finished all orders (i.e., the pairs of pickup and delivery)\n",
    "    # here the next vehicle will be selected!\n",
    "    vehicle_action_mask = (\n",
    "        torch.nn.functional.one_hot(\n",
    "            (td[\"current_vehicle_idx\"] + 1).clamp(max=self.num_vehicles - 1),\n",
    "            num_classes=self.num_vehicles,\n",
    "        )\n",
    "        .bool()\n",
    "    )\n",
    "\n",
    "    # \"Terminate\" action is allowed if\n",
    "    # (1) the current vehicle is not able to visit any pickup, and\n",
    "    # (2) the scheduled deliveries are all delivered\n",
    "    vehicle_action_mask[pd_action_mask.sum(dim=-1) > 0] = False\n",
    "\n",
    "    # Action mask is true when the action is allowed (i.e. feasible)\n",
    "    action_mask = torch.cat([pd_action_mask, vehicle_action_mask], dim=-1)\n",
    "    return action_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward function\n",
    "\n",
    "The `get_reward` function is used to evaluate the reward given the solution (actions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(self, td: TensorDict, actions: torch.Tensor) -> torch.Tensor:\n",
    "    locs = torch.cat(\n",
    "        [td[\"pickup_locs\"], td[\"vehicle_locs\"]], dim=-2\n",
    "    )\n",
    "    ordered_locs = gather_by_index(locs, actions)\n",
    "\n",
    "    if ordered_locs.dim() == 2:  # batch size = 1\n",
    "        ordered_locs = ordered_locs[None, ...]\n",
    "\n",
    "    # Reorder the tours in two dimensions\n",
    "    ordered_locs = rearrange(\n",
    "        ordered_locs,\n",
    "        \"... (n c) two -> ... n c two\",\n",
    "        n=self.num_vehicles,  # number of vehicles\n",
    "        c=self.capacity * 2 + 1,\n",
    "        two=2,\n",
    "    )  # batch, num vehicles, capacity, 2\n",
    "\n",
    "    dists = (ordered_locs[..., :-1, :] - ordered_locs[..., 1:, :]).norm(p=2, dim=-1) \n",
    "    dists = dists.sum(dim=(-1, -2))  # [batch]\n",
    "    return -dists # negative distance is the reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Action Specs\n",
    "\n",
    "This defines the input and output domains of the environment - similar to Gym's `spaces`. \n",
    "This is not strictly necessary, but it is useful to have a clear definition of the environment's action and observation spaces and if we want to sample actions using TorchRL's utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params: TensorDict = None):\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        pickup_locs=BoundedTensorSpec(\n",
    "            minimum=self.min_loc,\n",
    "            maximum=self.max_loc,\n",
    "            shape=(self.num_vehicles * self.capacity, 2),\n",
    "        ),\n",
    "        vehicle_locs=BoundedTensorSpec(\n",
    "            minimum=self.min_loc,\n",
    "            maximum=self.max_loc,\n",
    "            shape=(self.num_vehicles, 2),\n",
    "        ),\n",
    "        pickup_visited=UnboundedDiscreteTensorSpec(\n",
    "            shape=(self.num_vehicles * self.capacity), dtype=torch.int64\n",
    "        ),\n",
    "        current_vehicle_id=UnboundedDiscreteTensorSpec(shape=(1), dtype=torch.int64),\n",
    "        current_vehicle_loads=UnboundedDiscreteTensorSpec(\n",
    "            shape=(1), dtype=torch.int64\n",
    "        ),\n",
    "        current_vehicle_max_loads=UnboundedDiscreteTensorSpec(\n",
    "            shape=(1), dtype=torch.int64\n",
    "        ),\n",
    "        current_vehicle_pickup_visited=UnboundedDiscreteTensorSpec(\n",
    "            shape=(self.num_vehicles * self.capacity), dtype=torch.int64\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    self.input_spec = self.observation_spec.clone()\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        shape=(1,),\n",
    "        dtype=torch.int64,\n",
    "        minimum=0,\n",
    "        maximum=self.num_vehicles + self.num_vehicles * self.capacity * 2,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(1,))\n",
    "    self.done_spec = UnboundedDiscreteTensorSpec(shape=(1,), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "This function allows for generating data for training instances if no data is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(self, batch_size) -> TensorDict:\n",
    "    batch_size = [batch_size] if isinstance(batch_size, int) else batch_size\n",
    "\n",
    "    # Generate random locations\n",
    "    pickup_locs = (\n",
    "        torch.FloatTensor(*batch_size, self.num_vehicles * self.capacity, 2).uniform_(self.min_loc, self.max_loc).to(self.device)\n",
    "    )\n",
    "    vehicle_locs = (\n",
    "        torch.FloatTensor(*batch_size, self.num_vehicles, 2).uniform_(self.min_loc, self.max_loc).to(self.device)\n",
    "    )\n",
    "\n",
    "    return TensorDict(\n",
    "        {\n",
    "            \"pickup_locs\": pickup_locs,\n",
    "            \"vehicle_locs\": vehicle_locs,\n",
    "            \"first_node\": torch.zeros(\n",
    "                *batch_size, dtype=torch.int64, device=self.device\n",
    "            ),\n",
    "        },\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render function\n",
    "\n",
    "The `render` function is optional, but can be useful for quickly visualizing the results of your algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(\n",
    "    self,\n",
    "    td: TensorDict,\n",
    "    actions: torch.Tensor = None,\n",
    "    ax: Axes = None,\n",
    "    batch_idx: int = None,\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def draw_line(src, dst, ax):\n",
    "        ax.plot([src[0], dst[0]], [src[1], dst[1]], ls=\"--\", c=\"gray\")\n",
    "\n",
    "    td = td.detach().cpu()\n",
    "\n",
    "    if actions is None:\n",
    "        actions = td.get(\"action\", None)\n",
    "\n",
    "    if td.batch_size != torch.Size([]):\n",
    "        batch_idx = 0 if batch_idx is None else batch_idx\n",
    "        td = td[0]\n",
    "        actions = actions[0]\n",
    "\n",
    "    pickup_locs = td[\"pickup_locs\"]\n",
    "    vehicle_locs = td[\"vehicle_locs\"]\n",
    "\n",
    "    if ax is None:\n",
    "        # Create a plot of the nodes\n",
    "        _, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "    ax.axis(\"equal\"); ax.grid(True)\n",
    "\n",
    "    ax.scatter(pickup_locs[:, 0], pickup_locs[:, 1], marker=\"x\", color=\"gray\")\n",
    "\n",
    "\n",
    "    for v_i, (v_x, v_y) in enumerate(zip(vehicle_locs[:, 0], vehicle_locs[:, 1])):\n",
    "        ax.scatter(v_x, v_y, color=f\"C{v_i}\")\n",
    "\n",
    "    if actions is not None:  # draw solution if available.\n",
    "        sub_tours = actions.reshape(self.num_vehicles, -1)\n",
    "        loc = torch.cat([pickup_locs, vehicle_locs], dim=0)\n",
    "        for v_i, sub_tour in enumerate(sub_tours):\n",
    "            ax.plot(loc[sub_tour][:, 0], loc[sub_tour][:, 1], color=f\"C{v_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDPDPEnv(RL4COEnvBase):\n",
    "    \"\"\"Multi-Depot Pickup and Delivery Problem (MDPDP) environment\n",
    "    We consider the number of delivery locations to be num_vehicles * capacity,\n",
    "    with one corresponding pickup location for each delivery location.\n",
    "    The total number of locations will be:\n",
    "        - num_vehicles + (2 * num_vehicles * capacity)\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"MDPDP\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_vehicles: int = 5,\n",
    "        capacity: int = 3,\n",
    "        min_loc: float = 0.0,\n",
    "        max_loc: float = 1.0,\n",
    "        td_params: TensorDict = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_vehicles = num_vehicles\n",
    "        self.capacity = capacity\n",
    "        self.min_loc = min_loc\n",
    "        self.max_loc = max_loc\n",
    "        self._make_spec(td_params)\n",
    "        \n",
    "    _reset = _reset\n",
    "    _step = _step\n",
    "    get_reward = get_reward\n",
    "    get_action_mask = get_action_mask\n",
    "    _make_spec = _make_spec\n",
    "    generate_data = generate_data\n",
    "    render = render\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input_spec is protected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb 单元格 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m env \u001b[39m=\u001b[39m MDPDPEnv(num_vehicles\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, capacity\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reward, td, actions \u001b[39m=\u001b[39m rollout(env, env\u001b[39m.\u001b[39mreset(batch_size\u001b[39m=\u001b[39m[batch_size]), random_policy)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m env\u001b[39m.\u001b[39mrender(td, actions)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torchrl/envs/common.py:134\u001b[0m, in \u001b[0;36m_EnvPostInit.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 134\u001b[0m     instance: EnvBase \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    135\u001b[0m     \u001b[39m# we create the done spec by adding a done/terminated entry if one is missing\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     instance\u001b[39m.\u001b[39m_create_done_specs()\n",
      "\u001b[1;32m/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb 单元格 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_loc \u001b[39m=\u001b[39m min_loc\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_loc \u001b[39m=\u001b[39m max_loc\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_spec(td_params)\n",
      "\u001b[1;32m/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb 单元格 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_spec\u001b[39m(\u001b[39mself\u001b[39m, td_params: TensorDict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_spec \u001b[39m=\u001b[39m CompositeSpec(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         pickup_locs\u001b[39m=\u001b[39mBoundedTensorSpec(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             minimum\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_loc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         ),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_spec\u001b[39m.\u001b[39mclone()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_spec \u001b[39m=\u001b[39m BoundedTensorSpec(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         minimum\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         maximum\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_vehicles \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_vehicles \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapacity \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hexh/Library/CloudStorage/OneDrive-alu.hit.edu.cn/2-solving-new-problem.ipynb#X35sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_spec \u001b[39m=\u001b[39m UnboundedContinuousTensorSpec(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,))\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torchrl/envs/common.py:315\u001b[0m, in \u001b[0;36mEnvBase.__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_input_spec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_observation_spec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_done_spec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m ):\n\u001b[1;32m    311\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo set an environment spec, please use `env.observation_spec = obs_spec` (without the leading\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m underscore).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(key, value)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torch/nn/modules/module.py:1754\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     buffers[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1753\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1754\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/rl4co/lib/python3.10/site-packages/torchrl/envs/common.py:427\u001b[0m, in \u001b[0;36mEnvBase.input_spec\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m@input_spec\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m    426\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minput_spec\u001b[39m(\u001b[39mself\u001b[39m, value: TensorSpec) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minput_spec is protected.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input_spec is protected."
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "env = MDPDPEnv(num_vehicles=5, capacity=3)\n",
    "reward, td, actions = rollout(env, env.reset(batch_size=[batch_size]), random_policy)\n",
    "env.render(td, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now we need to model the problem by transforming input information into the latent space to be processed. In RL4CO, we divide embeddings in 3 parts:\n",
    "\n",
    "- `init_embedding`: embed initial states of the problem\n",
    "- `context_embedding`: embed context information of the problem for the current partial solution to modify the query \n",
    "- `dynamic_embedding`: embed dynamic information of the problem for the current partial solution to modify the query, key, and value (i.e. if other nodes also change state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Embedding\n",
    "\n",
    "Embed initial problem into latent space. In our case, we project the vehicle, pickup, and delivery locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDPDPInitEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        node_dim = 2  # x, y\n",
    "        self.init_embed_pick = nn.Linear(node_dim * 2, embedding_dim)\n",
    "        self.init_embed_vehicle = nn.Linear(2, embedding_dim)\n",
    "\n",
    "    def forward(self, td: TensorDict):\n",
    "        pickup_emb = self.init_embed_pick(\n",
    "            torch.cat([td[\"pickup_locs\"], td[\"delivery_locs\"]], dim=-1)\n",
    "        )\n",
    "        vehicle_emb = self.init_embed_vehicle(td[\"vehicle_locs\"])\n",
    "        return torch.cat([pickup_emb, vehicle_emb], dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Embedding\n",
    "\n",
    "Context embedding takes current context and returns a vector representation of it. In the MDPDP, the context is equivalent to the current node embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDPDPContextEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, step_context_dim=None, linear_bias=False):\n",
    "        super(MDPDPContextEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.W_placeholder = nn.Parameter(torch.Tensor(self.embedding_dim).uniform_(-1, 1))\n",
    "        self.project_context = nn.Linear(\n",
    "            embedding_dim, embedding_dim, bias=linear_bias\n",
    "        )\n",
    "        \n",
    "    def _cur_node_embedding(self, embeddings, td):\n",
    "        if td[\"i\"][0].item() == 0:\n",
    "            batch_size = embeddings.size(0)\n",
    "            context_embedding = self.W_placeholder[None, :].expand(\n",
    "                batch_size, self.W_placeholder.size(-1)\n",
    "            )\n",
    "            return context_embedding\n",
    "\n",
    "        cur_node_embedding = gather_by_index(embeddings, td[\"current_node\"])\n",
    "        return cur_node_embedding\n",
    "\n",
    "    def forward(self, embeddings, td):\n",
    "        cur_node_embedding = self._cur_node_embedding(embeddings, td).squeeze()\n",
    "        return self.project_context(cur_node_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Embedding\n",
    "\n",
    "Since the states do not change except for visited nodes, we do not need to modify the keys and values. Therefore, we set this to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticEmbedding(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(StaticEmbedding, self).__init__()\n",
    "\n",
    "    def forward(self, td):\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our environment\n",
    "env = MDPDPEnv(num_vehicles=5, capacity=3)\n",
    "\n",
    "# Instantiate policy with the embeddings we created above\n",
    "emb_dim = 128\n",
    "policy = AutoregressivePolicy(env,\n",
    "                              embedding_dim=emb_dim,\n",
    "                              init_embedding=MDPDPInitEmbedding(emb_dim),\n",
    "                              context_embedding=MDPDPContextEmbedding(emb_dim),\n",
    "                              dynamic_embedding=StaticEmbedding(emb_dim)\n",
    ")\n",
    "\n",
    "\n",
    "# Model: default is AM with REINFORCE and greedy rollout baseline\n",
    "model = AttentionModel(env, \n",
    "                       policy=policy,\n",
    "                       baseline='rollout',\n",
    "                       train_data_size=100_000,\n",
    "                       val_data_size=10_000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout untrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy rollouts over untrained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "td_init = env.reset(batch_size=[3]).to(device)\n",
    "model = model.to(device)\n",
    "out = model(td_init.clone(), phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "\n",
    "# Plotting\n",
    "print(f\"Tour lengths: {[f'{-r.item():.2f}' for r in out['reward']]}\")\n",
    "for td, actions in zip(td_init, out['actions'].cpu()):\n",
    "    env.render(td, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use our own wrapper around Lightning's `Trainer` to make it easier to use\n",
    "trainer = RL4COTrainer(max_epochs=3)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy rollouts over trained model (same states as previous plot)\n",
    "model = model.to(device)\n",
    "out = model(td_init, phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "\n",
    "# Plotting\n",
    "print(f\"Tour lengths: {[f'{-r.item():.2f}' for r in out['reward']]}\")\n",
    "for td, actions in zip(td_init, out['actions'].cpu()):\n",
    "    env.render(td, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that solutions are way better than with the untrained model, even just after 3 epochs! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
