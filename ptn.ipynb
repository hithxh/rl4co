{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hithx\\miniconda3\\envs\\optw_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg, use_tanh=False, clip_logits=10):\n",
    "        super().__init__()\n",
    "        self.use_tanh = use_tanh\n",
    "        self.W_q = nn.Linear(cfg.hidden, cfg.hidden, bias = True)\n",
    "        self.W_ref = nn.Conv1d(cfg.hidden, cfg.hidden, 1, 1)\n",
    "        self.clip_logits = clip_logits\n",
    "\n",
    "\n",
    "    def forward(self, query, ref, mask, inf = 1e8): \n",
    "        u1 = self.W_q(query).unsqueeze(-1).repeat(1,1,ref.size(1))# u1: (batch, 128, city_t)\n",
    "        u2 = self.W_ref(ref.permute(0,2,1))# u2: (batch, 128, city_t)\n",
    "        V = self.Vec.unsqueeze(0).unsqueeze(0).repeat(ref.size(0), 1, 1)\n",
    "        if self.use_tanh:\n",
    "            u = torch.bmm(V, torch.tanh(u1 + u2)).squeeze(1)\n",
    "            # V: (batch, 1, 128) * u1+u2: (batch, 128, city_t) => u: (batch, 1, city_t) => (batch, city_t)\n",
    "            u = u - inf * mask\n",
    "            a = F.softmax(u / self.softmax_T, dim = 1)\n",
    "            d = torch.bmm(u2, a.unsqueeze(2)).squeeze(2)\n",
    "            # u2: (batch, 128, city_t) * a: (batch, city_t, 1) => d: (batch, 128)\n",
    "        else:\n",
    "            u = torch.bmm(V, self.clip_logits * torch.tanh(u1 + u2)).squeeze(1)\n",
    "            # V: (batch, 1, 128) * u1+u2: (batch, 128, city_t) => u: (batch, 1, city_t) => (batch, city_t)\n",
    "            u = u - inf * mask\n",
    "            d = u\n",
    "        return d\n",
    "\n",
    "\n",
    "class Greedy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, log_p):\n",
    "        return torch.argmax(log_p, dim = 1).long()\n",
    "\n",
    "class Categorical(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, log_p):\n",
    "        return torch.multinomial(log_p.exp(), 1).long().squeeze(1)\n",
    "\n",
    "class Ptr_Actor(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.Embedding = nn.Linear(2, cfg.embed, bias = False)\n",
    "\n",
    "        # 输入 input, (h_0, c_0) input:(batch, seq, feature) \n",
    "        # 输出 output, (h_n, c_n) output:(batch, seq, D*H_out)\n",
    "        self.Encoder = nn.LSTM(input_size = cfg.embed, hidden_size = cfg.hidden, batch_first = True)\n",
    "        self.Decoder = nn.LSTM(input_size = cfg.embed, hidden_size = cfg.hidden, batch_first = True)\n",
    "        if torch.cuda.is_available():\n",
    "            self.Vec = nn.Parameter(torch.cuda.FloatTensor(cfg.embed))\n",
    "            self.Vec2 = nn.Parameter(torch.cuda.FloatTensor(cfg.embed))\n",
    "        else:\n",
    "            self.Vec = nn.Parameter(torch.FloatTensor(cfg.embed))\n",
    "            self.Vec2 = nn.Parameter(torch.FloatTensor(cfg.embed))\n",
    "        self.W_q = nn.Linear(cfg.hidden, cfg.hidden, bias = True)\n",
    "        self.W_ref = nn.Conv1d(cfg.hidden, cfg.hidden, 1, 1)\n",
    "        self.W_q2 = nn.Linear(cfg.hidden, cfg.hidden, bias = True)\n",
    "        self.W_ref2 = nn.Conv1d(cfg.hidden, cfg.hidden, 1, 1)\n",
    "        self.dec_input = nn.Parameter(torch.FloatTensor(cfg.embed))\n",
    "        self._initialize_weights(cfg.init_min, cfg.init_max)\n",
    "        self.clip_logits = cfg.clip_logits\n",
    "        self.softmax_T = cfg.softmax_T\n",
    "        self.n_glimpse = cfg.n_glimpse\n",
    "        self.city_selecter = {'greedy': Greedy(), 'sampling': Categorical()}.get(cfg.decode_type, None)\n",
    "        self.pointer = Attention(cfg, use_tanh=True, clip_logits=10)\n",
    "        self.glimpse = Attention(cfg, use_tanh=False, clip_logits=10)\n",
    "    \n",
    "    def _initialize_weights(self, init_min = -0.08, init_max = 0.08):\n",
    "        for param in self.parameters():\n",
    "            nn.init.uniform_(param.data, init_min, init_max)\n",
    "        \n",
    "    def forward(self, x, device):\n",
    "        '''\tx: (batch, city_t, 2)\n",
    "            enc_h: (batch, city_t, embed)\n",
    "            dec_input: (batch, 1, embed)\n",
    "            h: (1, batch, embed)\n",
    "            return: pi: (batch, city_t), ll: (batch)\n",
    "        '''\n",
    "        x = x.to(device)\n",
    "        batch, city_t, _ = x.size()\n",
    "        embed_enc_inputs = self.Embedding(x)\n",
    "        embed = embed_enc_inputs.size(2)\n",
    "        mask = torch.zeros((batch, city_t), device = device)\n",
    "        enc_h, (h, c) = self.Encoder(embed_enc_inputs, None)\n",
    "        ref = enc_h\n",
    "        pi_list, log_ps = [], []\n",
    "        dec_input = self.dec_input.unsqueeze(0).repeat(batch,1).unsqueeze(1).to(device)\n",
    "        for i in range(city_t):\n",
    "            _, (h, c) = self.Decoder(dec_input, (h, c))\n",
    "            query = h.squeeze(0)\n",
    "            for i in range(self.n_glimpse):\n",
    "                query = self.glimpse(query, ref, mask)\n",
    "            logits = self.pointer(query, ref, mask)\t\n",
    "            log_p = torch.log_softmax(logits, dim = -1)\n",
    "            next_node = self.city_selecter(log_p)\n",
    "            dec_input = torch.gather(input = embed_enc_inputs, dim = 1, index = next_node.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, embed))\n",
    "            \n",
    "            pi_list.append(next_node)\n",
    "            log_ps.append(log_p)\n",
    "            mask += torch.zeros((batch,city_t), device = device).scatter_(dim = 1, index = next_node.unsqueeze(1), value = 1)\n",
    "            \n",
    "        pi = torch.stack(pi_list, dim = 1)\n",
    "        ll = self.get_log_likelihood(torch.stack(log_ps, 1), pi)\n",
    "        return pi, ll \n",
    "    \n",
    "    # def glimpse(self, query, ref, mask, inf = 1e8):\n",
    "    # \t\"\"\"\t-ref about torch.bmm, torch.matmul and so on\n",
    "    # \t\thttps://qiita.com/tand826/items/9e1b6a4de785097fe6a5\n",
    "    # \t\thttps://qiita.com/shinochin/items/aa420e50d847453cc296\n",
    "            \n",
    "    # \t\t\tArgs: \n",
    "    # \t\tquery: the hidden state of the decoder at the current\n",
    "    # \t\t(batch, 128)\n",
    "    # \t\tref: the set of hidden states from the encoder. \n",
    "    # \t\t(batch, city_t, 128)\n",
    "    # \t\tmask: model only points at cities that have yet to be visited, so prevent them from being reselected\n",
    "    # \t\t(batch, city_t)\n",
    "    # \t\"\"\"\n",
    "    # \tu1 = self.W_q(query).unsqueeze(-1).repeat(1,1,ref.size(1))# u1: (batch, 128, city_t)\n",
    "    # \tu2 = self.W_ref(ref.permute(0,2,1))# u2: (batch, 128, city_t)\n",
    "    # \tV = self.Vec.unsqueeze(0).unsqueeze(0).repeat(ref.size(0), 1, 1)\n",
    "    # \tu = torch.bmm(V, torch.tanh(u1 + u2)).squeeze(1)\n",
    "    # \t# V: (batch, 1, 128) * u1+u2: (batch, 128, city_t) => u: (batch, 1, city_t) => (batch, city_t)\n",
    "    # \tu = u - inf * mask\n",
    "    # \ta = F.softmax(u / self.softmax_T, dim = 1)\n",
    "    # \td = torch.bmm(u2, a.unsqueeze(2)).squeeze(2)\n",
    "    # \t# u2: (batch, 128, city_t) * a: (batch, city_t, 1) => d: (batch, 128)\n",
    "    # \treturn d\n",
    "\n",
    "    # def pointer(self, query, ref, mask, inf = 1e8):\n",
    "    # \t\"\"\"\tArgs: \n",
    "    # \t\tquery: the hidden state of the decoder at the current\n",
    "    # \t\t(batch, 128)\n",
    "    # \t\tref: the set of hidden states from the encoder. \n",
    "    # \t\t(batch, city_t, 128)\n",
    "    # \t\tmask: model only points at cities that have yet to be visited, so prevent them from being reselected\n",
    "    # \t\t(batch, city_t)\n",
    "    # \t\"\"\"\n",
    "    # \tu1 = self.W_q2(query).unsqueeze(-1).repeat(1,1,ref.size(1))# u1: (batch, 128, city_t)\n",
    "    # \tu2 = self.W_ref2(ref.permute(0,2,1))# u2: (batch, 128, city_t)\n",
    "    # \tV = self.Vec2.unsqueeze(0).unsqueeze(0).repeat(ref.size(0), 1, 1)\n",
    "    # \tu = torch.bmm(V, self.clip_logits * torch.tanh(u1 + u2)).squeeze(1)\n",
    "    # \t# V: (batch, 1, 128) * u1+u2: (batch, 128, city_t) => u: (batch, 1, city_t) => (batch, city_t)\n",
    "    # \tu = u - inf * mask\n",
    "    # \treturn u\n",
    "    \n",
    "class Ptr_Critic(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.Embedding = nn.Linear(2, cfg.embed, bias = False)\n",
    "        self.Encoder = nn.LSTM(input_size = cfg.embed, hidden_size = cfg.hidden, batch_first = True)\n",
    "        self.Decoder = nn.LSTM(input_size = cfg.embed, hidden_size = cfg.hidden, batch_first = True)\n",
    "        if torch.cuda.is_available():\n",
    "            self.Vec = nn.Parameter(torch.cuda.FloatTensor(cfg.embed))\n",
    "        else:\n",
    "            self.Vec = nn.Parameter(torch.FloatTensor(cfg.embed))\n",
    "        self.W_q = nn.Linear(cfg.hidden, cfg.hidden, bias = True)\n",
    "        self.W_ref = nn.Conv1d(cfg.hidden, cfg.hidden, 1, 1)\n",
    "        # self.dec_input = nn.Parameter(torch.FloatTensor(cfg.embed))\n",
    "        self.final2FC = nn.Sequential(\n",
    "                    nn.Linear(cfg.hidden, cfg.hidden, bias = False),\n",
    "                    nn.ReLU(inplace = False),\n",
    "                    nn.Linear(cfg.hidden, 1, bias = False))\n",
    "        self._initialize_weights(cfg.init_min, cfg.init_max)\n",
    "        self.n_glimpse = cfg.n_glimpse\n",
    "        self.n_process = cfg.n_process\n",
    "        self.glimpse = Attention(cfg, use_tanh=False, clip_logits=10)\n",
    "    \n",
    "    def _initialize_weights(self, init_min = -0.08, init_max = 0.08):\n",
    "        for param in self.parameters():\n",
    "            nn.init.uniform_(param.data, init_min, init_max)\n",
    "            \n",
    "    def forward(self, x, device):\n",
    "        '''\tx: (batch, city_t, 2)\n",
    "            enc_h: (batch, city_t, embed)\n",
    "            query(Decoder input): (batch, 1, embed)\n",
    "            h: (1, batch, embed)\n",
    "            return: pred_l: (batch)\n",
    "        '''\n",
    "        x = x.to(device)\n",
    "        batch, city_t, xy = x.size()\n",
    "        embed_enc_inputs = self.Embedding(x)\n",
    "        embed = embed_enc_inputs.size(2)\n",
    "        enc_h, (h, c) = self.Encoder(embed_enc_inputs, None)\n",
    "        ref = enc_h\n",
    "        # ~ query = h.permute(1,0,2).to(device)# query = self.dec_input.unsqueeze(0).repeat(batch,1).unsqueeze(1).to(device)\n",
    "        query = h[-1]\n",
    "        # ~ process_h, process_c = [torch.zeros((1, batch, embed), device = device) for _ in range(2)]\n",
    "        for i in range(self.n_process):\n",
    "            # ~ _, (process_h, process_c) = self.Decoder(query, (process_h, process_c))\n",
    "            # ~ _, (h, c) = self.Decoder(query, (h, c))\n",
    "            # ~ query = query.squeeze(1)\n",
    "            for i in range(self.n_glimpse):\n",
    "                query = self.glimpse(query, ref)\n",
    "                # ~ query = query.unsqueeze(1)\n",
    "        '''\t\n",
    "        - page 5/15 in paper\n",
    "        critic model architecture detail is out there, \"Critic’s architecture for TSP\"\n",
    "        - page 14/15 in paper\n",
    "        glimpsing more than once with the same parameters \n",
    "        made the model less likely to learn and barely improved the results \n",
    "        \n",
    "        query(batch,hidden)*FC(hidden,hidden)*FC(hidden,1) -> pred_l(batch,1) ->pred_l(batch)\n",
    "        '''\n",
    "        pred_l = self.final2FC(query).squeeze(-1).squeeze(-1)\n",
    "        return pred_l \n",
    "    \n",
    "    # def glimpse(self, query, ref, infinity = 1e8):\n",
    "    # \t\"\"\"\tArgs: \n",
    "    # \t\tquery: the hidden state of the decoder at the current\n",
    "    # \t\t(batch, 128)\n",
    "    # \t\tref: the set of hidden states from the encoder. \n",
    "    # \t\t(batch, city_t, 128)\n",
    "    # \t\"\"\"\n",
    "    # \tu1 = self.W_q(query).unsqueeze(-1).repeat(1,1,ref.size(1))# u1: (batch, 128, city_t)\n",
    "    # \tu2 = self.W_ref(ref.permute(0,2,1))# u2: (batch, 128, city_t)\n",
    "    # \tV = self.Vec.unsqueeze(0).unsqueeze(0).repeat(ref.size(0), 1, 1)\n",
    "    # \tu = torch.bmm(V, torch.tanh(u1 + u2)).squeeze(1)\n",
    "    # \t# V: (batch, 1, 128) * u1+u2: (batch, 128, city_t) => u: (batch, 1, city_t) => (batch, city_t)\n",
    "    # \ta = F.softmax(u, dim = 1)\n",
    "    # \td = torch.bmm(u2, a.unsqueeze(2)).squeeze(2)\n",
    "    # \t# u2: (batch, 128, city_t) * a: (batch, city_t, 1) => d: (batch, 128)\n",
    "    # \treturn d\n",
    "\n",
    "\n",
    "class DRL(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.actor = Ptr_Actor()\n",
    "        self.critic = Ptr_Critic()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class MPSEnv():\n",
    "     pass\n",
    "\n",
    "class A2C:\n",
    "    def __init__(self) -> None:\n",
    "        self.actor = Ptr_Actor()\n",
    "        self.critic = Ptr_Critic()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        probs = self.actor(state)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        logp_action = m.log_prob(action)\n",
    "        return action, logp_action\n",
    "\n",
    "    def compute_value_loss(self, bs, blogp_a, br, bd, bns):\n",
    "        with torch.no_grad():\n",
    "            target_value = br\n",
    "        value_loss = F.mse_loss(self.critic(bs).squezze(), target_value)\n",
    "        return value_loss\n",
    "\n",
    "\n",
    "    def compute_policy_loss(self, bs, blogp_a, br, bd, bns):\n",
    "        with torch.no_grad():\n",
    "            target_value = br\n",
    "            adv = target_value - self.critic(bs).squeeze()\n",
    "        policy_loss = 0\n",
    "        for i, logp_a in enumerate(blogp_a):\n",
    "            policy_loss += -logp_a * adv[i]\n",
    "        policy_loss = policy_loss.mean()\n",
    "        return policy_loss\n",
    "\n",
    "    def update(self):\n",
    "        pass\n",
    "\n",
    "class INFO():\n",
    "    pass\n",
    "\n",
    "class Rollout():\n",
    "    pass\n",
    "    \n",
    "def train(cfg, env, agent):\n",
    "    V_optimizer = torch.optim.Adam(agent.V.parameters(), lr=3e-3)\n",
    "    pi_optimizer = torch.optim.Adam(agent.pi.parameters(), lr=3e-3)\n",
    "    info = INFO()\n",
    "\n",
    "    rollout = Rollout()\n",
    "    state, _ = env.reset()\n",
    "    for step in range(cfg.max_steps):\n",
    "        action, logp_action = agent.get_action(torch.tensor(state).float())\n",
    "        next_state, reward, terminited, truncated, _ = env.step(action.item())\n",
    "        done = terminited or truncated\n",
    "\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "        if done is True:\n",
    "            bs, ba, blogp_a, br, bd, bns = rollout.tensor()\n",
    "            value_loss = agent.compute_value_loss(bs, blogp_a, br, bd, bns)\n",
    "            V_optimizer.zero_grad()\n",
    "            value_loss.backward(retain_graph=True)\n",
    "            V_optimizer.step()\n",
    "\n",
    "            policy_loss = agent.compute_policy_loss(bs, blogp_a, br, bd, bns)\n",
    "            pi_optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            pi_optimizer.step()\n",
    "\n",
    "            agent.update()\n",
    "            state, _ = env.reset()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--env\", default=\"CartPole-v1\", type=str, help=\"Environment name.\")\n",
    "    parser.add_argument(\"--dim_state\", default=4, type=int, help=\"Dimension of state.\")\n",
    "    parser.add_argument(\"--num_action\", default=2, type=int, help=\"Number of action.\")\n",
    "    parser.add_argument(\"--output_dir\", default=\"output\", type=str, help=\"Output directory.\")\n",
    "    parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\n",
    "\n",
    "    parser.add_argument(\"--max_steps\", default=100_000, type=int, help=\"Maximum steps for interaction.\")\n",
    "    parser.add_argument(\"--discount\", default=0.99, type=float, help=\"Discount coefficient.\")\n",
    "    parser.add_argument(\"--lr\", default=1e-3, type=float, help=\"Learning rate.\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, help=\"Batch size.\")\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "\n",
    "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Train policy.\")\n",
    "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Evaluate policy.\")\n",
    "    cfg = parser.parse_args()\n",
    "    env = MPSEnv()\n",
    "    agent = A2C(cfg)\n",
    "    train(cfg, env, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
